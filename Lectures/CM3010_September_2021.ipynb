{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOLLHq/y3M5FquBYCfiFIm5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sreent/data-management-intro/blob/main/Lectures/CM3010_September_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1. Introduction**"
      ],
      "metadata": {
        "id": "OlkDuvXrirtU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook addresses **Question 2 (Bird Spotter)**, **Question 3 (MEI / MongoDB / RDF)**,\n",
        "and **Question 4 (Zoo DB)** from the attached exam.\n",
        "\n",
        "**Sections**:\n",
        "1. **Q2: Bird Spotter (MySQL)**\n",
        "2. **Q3: MEI with XML/XPath, MongoDB JSON, RDF, and SPARQL**\n",
        "3. **Q4: Zoo Database (MySQL)**\n",
        "\n",
        "We'll use Google Colab–style or local Jupyter setups with MySQL,\n",
        "plus `lxml` for XPath, `pymongo` for MongoDB, and `rdflib` for RDF/SPARQL."
      ],
      "metadata": {
        "id": "HkIA64RUizzS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Question 2 – Bird Spotter’s Records\n",
        "\n",
        "#### MySQL Setup for Question 2\n"
      ],
      "metadata": {
        "id": "88IfEX3Yi1rh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install MySQL (if in Colab/Ubuntu environment), start the service\n",
        "!apt -qq update > /dev/null\n",
        "!apt -y -qq install mysql-server > /dev/null\n",
        "!service mysql start\n",
        "\n",
        "# Create user & DB for bird spotting\n",
        "!mysql -e \"CREATE USER IF NOT EXISTS 'birduser'@'localhost' IDENTIFIED BY 'birdpass';\"\n",
        "!mysql -e \"CREATE DATABASE IF NOT EXISTS bird_spotter;\"\n",
        "!mysql -e \"GRANT ALL PRIVILEGES ON bird_spotter.* TO 'birduser'@'localhost';\"\n",
        "\n",
        "# Install Python libs\n",
        "!pip install -q sqlalchemy==2.0.20 ipython-sql==0.5.0 pymysql==1.1.0 prettytable==2.0.0\n",
        "\n",
        "%reload_ext sql\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 10)\n",
        "\n",
        "# Connect to bird_spotter DB\n",
        "%sql mysql+pymysql://birduser:birdpass@localhost/bird_spotter\n",
        "\n",
        "print(\"MySQL ready for Bird Spotter question (Q2).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPuxBVX5If8K",
        "outputId": "96036d77-5fba-44cc-d49a-071d7f911876"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            " * Starting MySQL database server mysqld\n",
            "su: warning: cannot change directory to /nonexistent: No such file or directory\n",
            "   ...done.\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMySQL ready for Bird Spotter question (Q2).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating a Denomalised Table for Bird Spotter (Q1)"
      ],
      "metadata": {
        "id": "DWorVGPNc0eQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "\n",
        "-- 1) Drop the Sightings table if it exists\n",
        "DROP TABLE IF EXISTS Sightings;\n",
        "\n",
        "-- 2) Create a denormalised Sightings table\n",
        "CREATE TABLE Sightings (\n",
        "  Species             VARCHAR(100),\n",
        "  Date                DATE,\n",
        "  NumberSighted       INT,\n",
        "  ConservationStatus  VARCHAR(50),\n",
        "  NatureReserve       VARCHAR(100),\n",
        "  Location            VARCHAR(50)\n",
        ");\n",
        "\n",
        "-- 3) Insert rows exactly as in the exam's sample data\n",
        "INSERT INTO Sightings\n",
        "  (Species, Date, NumberSighted, ConservationStatus, NatureReserve, Location)\n",
        "VALUES\n",
        "  ('Bar-tailed godwit',         '2021-04-21', 31, 'Least concern', 'Rainham Marshes', '51.5N 0.2E'),\n",
        "  ('Wood pigeon',               '2021-04-21', 31, 'Least concern', 'Rainham Marshes', '51.5N 0.2E'),\n",
        "  ('Greater spotted woodpecker','2021-06-13',  1, 'Least concern', 'Epping Forest',   '51.6N 0.0E'),\n",
        "  ('European turtle dove',      '2021-06-13',  2, 'Vulnerable',    'Epping Forest',   '51.6N 0.0E'),\n",
        "  ('Wood pigeon',               '2021-06-13',  2, 'Least concern', 'Epping Forest',   '51.6N 0.0E'),\n",
        "  ('Great bustard',             '2020-04-15',  3, 'Vulnerable',    'Salisbury Plain', '51.1N -1.8W'),\n",
        "  ('Bar-tailed godwit',         '2020-04-20', 53, 'Least concern', 'Rainham Marshes', '51.5N 0.2E');\n"
      ],
      "metadata": {
        "id": "-iO9M1Byc6-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2(a) Query: All Bird Types Seen Since 1 Jan 2021"
      ],
      "metadata": {
        "id": "3GsTPY5edP1q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQMtxLuXdbdC",
        "outputId": "1743f07b-b397-4218-dda4-e7017d411aba"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: %%sql is a cell magic, but the cell body is empty. Did you mean the line magic %sql (single %)?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Tables for Bird Spotter (Q2)\n",
        "\n",
        "Based on the question’s data:\n",
        "\n",
        "- **NatureReserves** table:\n",
        "  - PK: `NatureReserveName` (VARCHAR)\n",
        "  - `Location` (stores latitude/longitude as a single string)\n",
        "\n",
        "- **Species** table:\n",
        "  - PK: `SpeciesName`\n",
        "  - Fields:\n",
        "    - `ConservationStatus` (VARCHAR)\n",
        "\n",
        "- **Sightings** table:\n",
        "  - Composite PK: `(SpeciesName, NatureReserveName, Date)`\n",
        "  - Fields:\n",
        "    - `SpeciesName` (FK references Species)\n",
        "    - `NatureReserveName` (FK references NatureReserves)\n",
        "    - `Date` (DATE)\n",
        "    - `NumberSighted` (INT)"
      ],
      "metadata": {
        "id": "TV1zWijHi9QO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "DROP TABLE IF EXISTS Sightings;\n",
        "DROP TABLE IF EXISTS NatureReserves;\n",
        "DROP TABLE IF EXISTS Spcies;\n",
        "\n",
        "CREATE TABLE NatureReserves (\n",
        "  NatureReserveName VARCHAR(100) PRIMARY KEY,\n",
        "  Location VARCHAR(50)\n",
        ");\n",
        "\n",
        "CREATE TABLE Species (\n",
        "  SpeciesName VARCHAR(100) PRIMARY KEY,\n",
        "  ConservationStatus VARCHAR(50)\n",
        ");\n",
        "\n",
        "CREATE TABLE Sightings (\n",
        "  SpeciesName VARCHAR(100),\n",
        "  NatureReserveName VARCHAR(100),\n",
        "  Date DATE,\n",
        "  NumberSighted INT,\n",
        "  PRIMARY KEY (SpeciesName, NatureReserveName, Date),\n",
        "  FOREIGN KEY (SpeciesName) REFERENCES Species(SpeciesName),\n",
        "  FOREIGN KEY (NatureReserveName) REFERENCES NatureReserves(NatureReserveName)\n",
        ");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OYtc18xiug6",
        "outputId": "e2e2e4d6-3000-4130-ed35-b8c9d3a1cca2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * mysql+pymysql://birduser:***@localhost/bird_spotter\n",
            "0 rows affected.\n",
            "0 rows affected.\n",
            "0 rows affected.\n",
            "0 rows affected.\n",
            "0 rows affected.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Insert the Exact Rows from the Question"
      ],
      "metadata": {
        "id": "6ioy4m-3izT1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "\n",
        "-- Insert data into NatureReserves\n",
        "INSERT IGNORE INTO NatureReserves (NatureReserveName, Location) VALUES\n",
        "('Rainham Marshes',  '51.5N 0.2E'),\n",
        "('Epping Forest',    '51.6N 0.0E'),\n",
        "('Salisbury Plain',  '51.1N -1.8W');\n",
        "\n",
        "-- Insert data into Species\n",
        "INSERT IGNORE INTO Species (SpeciesName, ConservationStatus) VALUES\n",
        "('Bar-tailed godwit',         'Least concern'),\n",
        "('Wood pigeon',               'Least concern'),\n",
        "('Greater spotted woodpecker','Least concern'),\n",
        "('European turtle dove',      'Vulnerable'),\n",
        "('Great bustard',             'Vulnerable');\n",
        "\n",
        "-- Insert data into Sightings\n",
        "-- We use the species, nature reserve, date, and number sighted from the exam table.\n",
        "INSERT IGNORE INTO Sightings (SpeciesName, NatureReserveName, Date, NumberSighted)\n",
        "VALUES\n",
        "('Bar-tailed godwit',         'Rainham Marshes', '2021-04-21', 31),\n",
        "('Wood pigeon',               'Rainham Marshes', '2021-04-21', 31),\n",
        "('Greater spotted woodpecker','Epping Forest',   '2021-06-13', 1),\n",
        "('European turtle dove',      'Epping Forest',   '2021-06-13', 2),\n",
        "('Wood pigeon',               'Epping Forest',   '2021-06-13', 2),\n",
        "('Great bustard',             'Salisbury Plain', '2020-04-15', 3),\n",
        "('Bar-tailed godwit',         'Rainham Marshes', '2020-04-20', 53);\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cd42x1haKbVC",
        "outputId": "32c50a64-683a-48e7-b44e-f52b03874776"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * mysql+pymysql://birduser:***@localhost/bird_spotter\n",
            "3 rows affected.\n",
            "5 rows affected.\n",
            "7 rows affected.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2(e) Query: Bird Types & Their Conservation Status Since 2021-01-01\n"
      ],
      "metadata": {
        "id": "Y0CU9RXcjH8z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnnyQejdkYxg",
        "outputId": "6ffb3a53-1da6-4018-89ba-77546db9a49e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * mysql+pymysql://birduser:***@localhost/bird_spotter\n",
            "0 rows affected.\n",
            "0 rows affected.\n",
            "0 rows affected.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2(f) - Transaction Example\n",
        "\n",
        "Imagine we need to insert a new sighting + update something about\n",
        "a bird's conservation status in one atomic step."
      ],
      "metadata": {
        "id": "bKDsz95mkkgn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "START TRANSACTION;\n",
        "\n",
        "INSERT INTO Sightings\n",
        "(SpeciesName, NatureReserveName, Date, NumberSighted, ConservationStatus)\n",
        "VALUES\n",
        "('Test bird', 'Rainham Marshes', '2021-08-01', 5, 'Least concern');\n",
        "\n",
        "UPDATE Sightings\n",
        "SET ConservationStatus = 'Endangered'\n",
        "WHERE SpeciesName='Test bird'\n",
        "  AND NatureReserveName='Rainham Marshes'\n",
        "  AND Date='2021-08-01';\n",
        "\n",
        "/*\n",
        "-- Optionally COMMIT or ROLLBACK:\n",
        "COMMIT;\n",
        "-- or\n",
        "ROLLBACK;\n",
        "*/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9KU3GhDMkvg_",
        "outputId": "a84a016f-a8c0-46a1-c96e-7ef18c05165a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * mysql+pymysql://birduser:***@localhost/bird_spotter\n",
            "4 rows affected.\n",
            "2 rows affected.\n",
            "5 rows affected.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Question 3 – MEI XML, MongoDB, RDF/SPARQL\n",
        "\n",
        "We’ll define an MEI snippet with `<measure>`, `<staff n=\"2\">`, `<staff n=\"3\">` etc.,\n",
        "mirroring the question.\n",
        "\n",
        "We'll parse it via XPath, do the chord → JSON translation,\n",
        "a MongoDB example, and an RDF example with SPARQL."
      ],
      "metadata": {
        "id": "L3HfNJbVklpD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install `lxml` and Parse the MEI Snippet"
      ],
      "metadata": {
        "id": "gPbEMywAMGxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lxml\n",
        "from lxml import etree\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "mei_data = \"\"\"\n",
        "<measure>\n",
        "  <staff n=\"2\">\n",
        "    <layer n=\"1\">\n",
        "      <chord xml:id=\"d13e1\" dur=\"8\" dur.ppq=\"12\" stem.dir=\"up\">\n",
        "        <note xml:id=\"d1e101\" pname=\"c\" oct=\"5\"/>\n",
        "        <note xml:id=\"d1e118\" pname=\"a\" oct=\"4\"/>\n",
        "        <note xml:id=\"d1e136\" pname=\"c\" oct=\"4\"/>\n",
        "      </chord>\n",
        "    </layer>\n",
        "  </staff>\n",
        "  <staff n=\"3\">\n",
        "    <layer n=\"1\">\n",
        "      <chord xml:id=\"d17e1\" dur=\"8\" dur.ppq=\"12\" stem.dir=\"up\">\n",
        "        <note xml:id=\"d1e157\" pname=\"f\" oct=\"3\"/>\n",
        "        <note xml:id=\"d1e174\" pname=\"f\" oct=\"2\"/>\n",
        "      </chord>\n",
        "    </layer>\n",
        "  </staff>\n",
        "</measure>\n",
        "\"\"\"\n",
        "\n",
        "root_mei = etree.fromstring(mei_data)\n",
        "print(\"MEI snippet parsed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAsItN71PlLU",
        "outputId": "3db4074e-45e7-410b-97bb-d5b048495167"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (5.3.0)\n",
            "MEI snippet parsed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### XPath Queries for Q3(b)"
      ],
      "metadata": {
        "id": "OeeDjE9DMZd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_xml(nodes):\n",
        "    for node in nodes:\n",
        "        xml_str = etree.tostring(node, pretty_print=True, encoding='unicode').strip()\n",
        "        display(Markdown(f\"```xml\\n{xml_str}\\n```\"))"
      ],
      "metadata": {
        "id": "hyxIleaYMiSl"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Suppose we want all chords in staff n=\"2\" containing notes with pname=\"f\"\n",
        "chords_with_f_in_staff2 = root_mei.xpath('/staff[n=\"2\"]/layer/chord[note/@pname=\"c\"]')\n",
        "display_xml(chords_with_f_in_staff2)\n",
        "\n",
        "# If the question specifically wants \"pname='c' or 'f'\", just adjust the filter."
      ],
      "metadata": {
        "id": "vOu8zorQPkUg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3(c) i. Translate the *first chord* (which has xml:id=\"d13e1\") into JSON"
      ],
      "metadata": {
        "id": "tS92tjgNNlnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "# Let's find the chord with xml:id=\"d13e1\"\n",
        "chord_el = root_mei.xpath('//chord[@xml:id=\"d13e1\"]')[0]\n",
        "\n",
        "# Build a Python dict:\n",
        "# Access the 'xml:id' attribute correctly using the namespace\n",
        "chord_dict = {\n",
        "    \"xml:id\": chord_el.attrib.get(\"{http://www.w3.org/XML/1998/namespace}id\"),\n",
        "    \"dur\": chord_el.attrib[\"dur\"],\n",
        "    \"dur.ppq\": chord_el.attrib[\"dur.ppq\"],\n",
        "    \"stem.dir\": chord_el.attrib[\"stem.dir\"],\n",
        "    \"notes\": []\n",
        "}\n",
        "\n",
        "for note_el in chord_el.xpath('./note'):\n",
        "    # Access the 'xml:id' attribute correctly using the namespace for notes as well\n",
        "    note_info = {\n",
        "        \"xml:id\": note_el.attrib.get(\"{http://www.w3.org/XML/1998/namespace}id\"),\n",
        "        \"pname\": note_el.attrib[\"pname\"],\n",
        "        \"oct\": note_el.attrib[\"oct\"],\n",
        "    }\n",
        "    chord_dict[\"notes\"].append(note_info)\n",
        "\n",
        "json_chord = json.dumps(chord_dict, indent=2)\n",
        "print(json_chord)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQvvkLE_Nq2-",
        "outputId": "acfdfbd7-60f7-4d7b-86a6-ccd2fea41f56"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"xml:id\": \"d13e1\",\n",
            "  \"dur\": \"8\",\n",
            "  \"dur.ppq\": \"12\",\n",
            "  \"stem.dir\": \"up\",\n",
            "  \"notes\": [\n",
            "    {\n",
            "      \"xml:id\": \"d1e101\",\n",
            "      \"pname\": \"c\",\n",
            "      \"oct\": \"5\"\n",
            "    },\n",
            "    {\n",
            "      \"xml:id\": \"d1e118\",\n",
            "      \"pname\": \"a\",\n",
            "      \"oct\": \"4\"\n",
            "    },\n",
            "    {\n",
            "      \"xml:id\": \"d1e136\",\n",
            "      \"pname\": \"c\",\n",
            "      \"oct\": \"4\"\n",
            "    }\n",
            "  ]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3(c) ii. If the whole data structure was an array of chord objects in MongoDB,\n",
        "here is a `find` command to return only chords with:\n",
        "- `stem.dir = \"up\"`\n",
        "- at least one note with `pname=\"f\"`"
      ],
      "metadata": {
        "id": "6OagoZT8OhQW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Cell 14: MongoDB Setup + `find` Example (Code)**"
      ],
      "metadata": {
        "id": "jq5sZhw3On-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install MongoDB's dependencies\n",
        "!sudo wget http://archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1f-1ubuntu2_amd64.deb\n",
        "!sudo dpkg -i libssl1.1_1.1.1f-1ubuntu2_amd64.deb\n",
        "\n",
        "# Import the public key used by the package management system\n",
        "!wget -qO - https://www.mongodb.org/static/pgp/server-4.4.asc | apt-key add -\n",
        "\n",
        "# Create a list file for MongoDB\n",
        "!echo \"deb [ arch=amd64,arm64 ] http://repo.mongodb.org/apt/ubuntu bionic/mongodb-org/4.4 multiverse\" | tee /etc/apt/sources.list.d/mongodb-org-4.4.list\n",
        "\n",
        "# Reload the local package database\n",
        "!apt-get update > /dev/null\n",
        "\n",
        "# Install the MongoDB packages\n",
        "!apt-get install -y mongodb-org > /dev/null\n",
        "\n",
        "# Install pymongo\n",
        "!pip install -q pymongo\n",
        "\n",
        "# Create Data Folder\n",
        "!mkdir -p /data/db\n",
        "\n",
        "# Start MongoDB\n",
        "!mongod --fork --logpath /var/log/mongodb.log --dbpath /data/db\n",
        "\n",
        "from pymongo import MongoClient\n",
        "\n",
        "# Establish connection to MongoDB\n",
        "try:\n",
        "    client = MongoClient('localhost', 27017)\n",
        "    print(\"Connected to MongoDB\")\n",
        "except Exception as e:\n",
        "    print(\"Error connecting to MongoDB: \", e)\n",
        "    exit()\n",
        "\n",
        "# List databases to check the connection\n",
        "try:\n",
        "    databases = client.list_database_names()\n",
        "    print(\"Databases:\", databases)\n",
        "except Exception as e:\n",
        "    print(\"Error listing databases: \", e)\n",
        "\n",
        "# Retrieve server status\n",
        "try:\n",
        "    server_status = client.admin.command(\"serverStatus\")\n",
        "    print(\"Server Status:\", server_status)\n",
        "except Exception as e:\n",
        "    print(\"Error retrieving server status: \", e)\n",
        "\n",
        "# Perform basic database operations (Create, Read)\n",
        "try:\n",
        "    db = client.test_db\n",
        "    collection = db.test_collection\n",
        "    # Insert a document\n",
        "    insert_result = collection.insert_one({\"name\": \"test\", \"value\": 123})\n",
        "    print(\"Insert operation result:\", insert_result.inserted_id)\n",
        "    # Read a document\n",
        "    read_result = collection.find_one({\"name\": \"test\"})\n",
        "    print(\"Read operation result:\", read_result)\n",
        "except Exception as e:\n",
        "    print(\"Error performing database operations: \", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyzsDPLoPzUL",
        "outputId": "9ca00b12-bc69-4df3-a587-acd6d3fbf779"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-18 02:29:20--  http://archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1f-1ubuntu2_amd64.deb\n",
            "Resolving archive.ubuntu.com (archive.ubuntu.com)... 91.189.91.81, 91.189.91.82, 91.189.91.83, ...\n",
            "Connecting to archive.ubuntu.com (archive.ubuntu.com)|91.189.91.81|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1318204 (1.3M) [application/vnd.debian.binary-package]\n",
            "Saving to: ‘libssl1.1_1.1.1f-1ubuntu2_amd64.deb’\n",
            "\n",
            "libssl1.1_1.1.1f-1u 100%[===================>]   1.26M  2.79MB/s    in 0.4s    \n",
            "\n",
            "2025-01-18 02:29:20 (2.79 MB/s) - ‘libssl1.1_1.1.1f-1ubuntu2_amd64.deb’ saved [1318204/1318204]\n",
            "\n",
            "Selecting previously unselected package libssl1.1:amd64.\n",
            "(Reading database ... 125097 files and directories currently installed.)\n",
            "Preparing to unpack libssl1.1_1.1.1f-1ubuntu2_amd64.deb ...\n",
            "Unpacking libssl1.1:amd64 (1.1.1f-1ubuntu2) ...\n",
            "Setting up libssl1.1:amd64 (1.1.1f-1ubuntu2) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "OK\n",
            "deb [ arch=amd64,arm64 ] http://repo.mongodb.org/apt/ubuntu bionic/mongodb-org/4.4 multiverse\n",
            "W: http://repo.mongodb.org/apt/ubuntu/dists/bionic/mongodb-org/4.4/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "about to fork child process, waiting until server is ready for connections.\n",
            "forked process: 11398\n",
            "child process started successfully, parent exiting\n",
            "Connected to MongoDB\n",
            "Databases: ['admin', 'config', 'local']\n",
            "Server Status: {'host': '790e4a542fde', 'version': '4.4.29', 'process': 'mongod', 'pid': 11398, 'uptime': 1.0, 'uptimeMillis': 877, 'uptimeEstimate': 0, 'localTime': datetime.datetime(2025, 1, 18, 2, 29, 53, 254000), 'asserts': {'regular': 0, 'warning': 0, 'msg': 0, 'user': 4, 'rollovers': 0}, 'connections': {'current': 3, 'available': 838857, 'totalCreated': 3, 'active': 2, 'exhaustIsMaster': 0, 'exhaustHello': 0, 'awaitingTopologyChanges': 1}, 'electionMetrics': {'stepUpCmd': {'called': 0, 'successful': 0}, 'priorityTakeover': {'called': 0, 'successful': 0}, 'catchUpTakeover': {'called': 0, 'successful': 0}, 'electionTimeout': {'called': 0, 'successful': 0}, 'freezeTimeout': {'called': 0, 'successful': 0}, 'numStepDownsCausedByHigherTerm': 0, 'numCatchUps': 0, 'numCatchUpsSucceeded': 0, 'numCatchUpsAlreadyCaughtUp': 0, 'numCatchUpsSkipped': 0, 'numCatchUpsTimedOut': 0, 'numCatchUpsFailedWithError': 0, 'numCatchUpsFailedWithNewTerm': 0, 'numCatchUpsFailedWithReplSetAbortPrimaryCatchUpCmd': 0, 'averageCatchUpOps': 0.0}, 'extra_info': {'note': 'fields vary by platform', 'user_time_us': 635396, 'system_time_us': 46641, 'maximum_resident_set_kb': 84284, 'input_blocks': 0, 'output_blocks': 328, 'page_reclaims': 12485, 'page_faults': 0, 'voluntary_context_switches': 174, 'involuntary_context_switches': 108}, 'featureCompatibilityVersion': {'major': 4, 'minor': 4, 'transitioning': 0}, 'flowControl': {'enabled': True, 'targetRateLimit': 1000000000, 'timeAcquiringMicros': 2, 'locksPerKiloOp': 0.0, 'sustainerRate': 0, 'isLagged': False, 'isLaggedCount': 0, 'isLaggedTimeMicros': 0}, 'globalLock': {'totalTime': 896000, 'currentQueue': {'total': 0, 'readers': 0, 'writers': 0}, 'activeClients': {'total': 0, 'readers': 0, 'writers': 0}}, 'indexBulkBuilder': {'count': 0, 'filesOpenedForExternalSort': 0, 'filesClosedForExternalSort': 0}, 'locks': {'ParallelBatchWriterMode': {'acquireCount': {'r': 23}}, 'FeatureCompatibilityVersion': {'acquireCount': {'r': 15, 'w': 13}}, 'ReplicationStateTransition': {'acquireCount': {'w': 28}}, 'Global': {'acquireCount': {'r': 15, 'w': 9, 'W': 4}}, 'Database': {'acquireCount': {'r': 14, 'w': 3, 'W': 6}}, 'Collection': {'acquireCount': {'r': 20, 'w': 4, 'W': 2}}, 'Mutex': {'acquireCount': {'r': 24}}}, 'logicalSessionRecordCache': {'activeSessionsCount': 1, 'sessionsCollectionJobCount': 1, 'lastSessionsCollectionJobDurationMillis': 35, 'lastSessionsCollectionJobTimestamp': datetime.datetime(2025, 1, 18, 2, 29, 53, 172000), 'lastSessionsCollectionJobEntriesRefreshed': 0, 'lastSessionsCollectionJobEntriesEnded': 0, 'lastSessionsCollectionJobCursorsClosed': 0, 'transactionReaperJobCount': 1, 'lastTransactionReaperJobDurationMillis': 0, 'lastTransactionReaperJobTimestamp': datetime.datetime(2025, 1, 18, 2, 29, 53, 173000), 'lastTransactionReaperJobEntriesCleanedUp': 0, 'sessionCatalogSize': 0}, 'network': {'bytesIn': 1269, 'bytesOut': 1114, 'physicalBytesIn': 1269, 'physicalBytesOut': 1114, 'numSlowDNSOperations': 0, 'numSlowSSLOperations': 0, 'numRequests': 6, 'tcpFastOpen': {'kernelSetting': 1, 'serverSupported': True, 'clientSupported': True, 'accepted': 0}, 'compression': {'snappy': {'compressor': {'bytesIn': 0, 'bytesOut': 0}, 'decompressor': {'bytesIn': 0, 'bytesOut': 0}}, 'zstd': {'compressor': {'bytesIn': 0, 'bytesOut': 0}, 'decompressor': {'bytesIn': 0, 'bytesOut': 0}}, 'zlib': {'compressor': {'bytesIn': 0, 'bytesOut': 0}, 'decompressor': {'bytesIn': 0, 'bytesOut': 0}}}, 'serviceExecutorTaskStats': {'executor': 'passthrough', 'threadsRunning': 3}}, 'opLatencies': {'reads': {'latency': 0, 'ops': 0}, 'writes': {'latency': 0, 'ops': 0}, 'commands': {'latency': 346, 'ops': 4}, 'transactions': {'latency': 0, 'ops': 0}}, 'opReadConcernCounters': {'available': 0, 'linearizable': 0, 'local': 0, 'majority': 0, 'snapshot': 0, 'none': 1}, 'opcounters': {'insert': 0, 'query': 1, 'update': 0, 'delete': 0, 'getmore': 0, 'command': 9}, 'opcountersRepl': {'insert': 0, 'query': 0, 'update': 0, 'delete': 0, 'getmore': 0, 'command': 0}, 'scramCache': {'SCRAM-SHA-1': {'count': 0, 'hits': 0, 'misses': 0}, 'SCRAM-SHA-256': {'count': 0, 'hits': 0, 'misses': 0}}, 'security': {'authentication': {'mechanisms': {'MONGODB-X509': {'speculativeAuthenticate': {'received': 0, 'successful': 0}, 'authenticate': {'received': 0, 'successful': 0}}, 'SCRAM-SHA-1': {'speculativeAuthenticate': {'received': 0, 'successful': 0}, 'authenticate': {'received': 0, 'successful': 0}}, 'SCRAM-SHA-256': {'speculativeAuthenticate': {'received': 0, 'successful': 0}, 'authenticate': {'received': 0, 'successful': 0}}}}}, 'storageEngine': {'name': 'wiredTiger', 'supportsCommittedReads': True, 'oldestRequiredTimestampForCrashRecovery': Timestamp(0, 0), 'supportsPendingDrops': True, 'dropPendingIdents': 0, 'supportsTwoPhaseIndexBuild': True, 'supportsSnapshotReadConcern': True, 'readOnly': False, 'persistent': True, 'backupCursorOpen': False}, 'tcmalloc': {'generic': {'current_allocated_bytes': 89233960, 'heap_size': 90484736}, 'tcmalloc': {'pageheap_free_bytes': 557056, 'pageheap_unmapped_bytes': 0, 'max_total_thread_cache_bytes': 1073741824, 'current_total_thread_cache_bytes': 459184, 'total_free_bytes': 693720, 'central_cache_free_bytes': 203816, 'transfer_cache_free_bytes': 30720, 'thread_cache_free_bytes': 459184, 'aggressive_memory_decommit': 0, 'pageheap_committed_bytes': 90484736, 'pageheap_scavenge_count': 0, 'pageheap_commit_count': 52, 'pageheap_total_commit_bytes': 90484736, 'pageheap_decommit_count': 0, 'pageheap_total_decommit_bytes': 0, 'pageheap_reserve_count': 52, 'pageheap_total_reserve_bytes': 90484736, 'spinlock_total_delay_ns': 0, 'release_rate': 1.0, 'formattedString': '------------------------------------------------\\nMALLOC:       89234536 (   85.1 MiB) Bytes in use by application\\nMALLOC: +       557056 (    0.5 MiB) Bytes in page heap freelist\\nMALLOC: +       201512 (    0.2 MiB) Bytes in central cache freelist\\nMALLOC: +        30720 (    0.0 MiB) Bytes in transfer cache freelist\\nMALLOC: +       460912 (    0.4 MiB) Bytes in thread cache freelists\\nMALLOC: +      2752512 (    2.6 MiB) Bytes in malloc metadata\\nMALLOC:   ------------\\nMALLOC: =     93237248 (   88.9 MiB) Actual memory used (physical + swap)\\nMALLOC: +            0 (    0.0 MiB) Bytes released to OS (aka unmapped)\\nMALLOC:   ------------\\nMALLOC: =     93237248 (   88.9 MiB) Virtual address space used\\nMALLOC:\\nMALLOC:            656              Spans in use\\nMALLOC:             31              Thread heaps in use\\nMALLOC:           4096              Tcmalloc page size\\n------------------------------------------------\\nCall ReleaseFreeMemory() to release freelist memory to the OS (via madvise()).\\nBytes released to the OS take up virtual address space but no physical memory.\\n'}}, 'trafficRecording': {'running': False}, 'transactions': {'retriedCommandsCount': 0, 'retriedStatementsCount': 0, 'transactionsCollectionWriteCount': 0, 'currentActive': 0, 'currentInactive': 0, 'currentOpen': 0, 'totalAborted': 0, 'totalCommitted': 0, 'totalStarted': 0, 'totalPrepared': 0, 'totalPreparedThenCommitted': 0, 'totalPreparedThenAborted': 0, 'currentPrepared': 0}, 'transportSecurity': {'1.0': 0, '1.1': 0, '1.2': 0, '1.3': 0, 'unknown': 0}, 'twoPhaseCommitCoordinator': {'totalCreated': 0, 'totalStartedTwoPhaseCommit': 0, 'totalAbortedTwoPhaseCommit': 0, 'totalCommittedTwoPhaseCommit': 0, 'currentInSteps': {'writingParticipantList': 0, 'waitingForVotes': 0, 'writingDecision': 0, 'waitingForDecisionAcks': 0, 'deletingCoordinatorDoc': 0}}, 'wiredTiger': {'uri': 'statistics:', 'block-manager': {'blocks pre-loaded': 0, 'blocks read': 0, 'blocks written': 0, 'bytes read': 0, 'bytes read via memory map API': 0, 'bytes read via system call API': 0, 'bytes written': 0, 'bytes written for checkpoint': 0, 'bytes written via memory map API': 0, 'bytes written via system call API': 0, 'mapped blocks read': 0, 'mapped bytes read': 0, 'number of times the file was remapped because it changed size via fallocate or truncate': 0, 'number of times the region was remapped via write': 0}, 'cache': {'application threads page read from disk to cache count': 0, 'application threads page read from disk to cache time (usecs)': 0, 'application threads page write from cache to disk count': 0, 'application threads page write from cache to disk time (usecs)': 0, 'bytes allocated for updates': 30877, 'bytes belonging to page images in the cache': 0, 'bytes belonging to the history store table in the cache': 191, 'bytes currently in the cache': 33705, 'bytes dirty in the cache cumulative': 3832, 'bytes not belonging to page images in the cache': 33705, 'bytes read into cache': 0, 'bytes written from cache': 0, 'cache overflow score': 0, 'checkpoint blocked page eviction': 0, 'checkpoint of history store file blocked non-history store page eviction': 0, 'eviction calls to get a page': 3, 'eviction calls to get a page found queue empty': 3, 'eviction calls to get a page found queue empty after locking': 0, 'eviction currently operating in aggressive mode': 0, 'eviction empty score': 0, 'eviction gave up due to detecting an out of order on disk value behind the last update on the chain': 0, 'eviction gave up due to detecting an out of order tombstone ahead of the selected on disk update': 0, 'eviction gave up due to detecting an out of order tombstone ahead of the selected on disk update after validating the update chain': 0, 'eviction gave up due to detecting out of order timestamps on the update chain after the selected on disk update': 0, 'eviction passes of a file': 0, 'eviction server candidate queue empty when topping up': 0, 'eviction server candidate queue not empty when topping up': 0, 'eviction server evicting pages': 0, 'eviction server slept, because we did not make progress with eviction': 0, 'eviction server unable to reach eviction goal': 0, 'eviction server waiting for a leaf page': 10, 'eviction state': 64, 'eviction walk most recent sleeps for checkpoint handle gathering': 0, 'eviction walk target pages histogram - 0-9': 0, 'eviction walk target pages histogram - 10-31': 0, 'eviction walk target pages histogram - 128 and higher': 0, 'eviction walk target pages histogram - 32-63': 0, 'eviction walk target pages histogram - 64-128': 0, 'eviction walk target pages reduced due to history store cache pressure': 0, 'eviction walk target strategy both clean and dirty pages': 0, 'eviction walk target strategy only clean pages': 0, 'eviction walk target strategy only dirty pages': 0, 'eviction walks abandoned': 0, 'eviction walks gave up because they restarted their walk twice': 0, 'eviction walks gave up because they saw too many pages and found no candidates': 0, 'eviction walks gave up because they saw too many pages and found too few candidates': 0, 'eviction walks reached end of tree': 0, 'eviction walks restarted': 0, 'eviction walks started from root of tree': 0, 'eviction walks started from saved location in tree': 0, 'eviction worker thread active': 4, 'eviction worker thread created': 0, 'eviction worker thread evicting pages': 0, 'eviction worker thread removed': 0, 'eviction worker thread stable number': 0, 'files with active eviction walks': 0, 'files with new eviction walks started': 0, 'force re-tuning of eviction workers once in a while': 0, 'forced eviction - history store pages failed to evict while session has history store cursor open': 0, 'forced eviction - history store pages selected while session has history store cursor open': 0, 'forced eviction - history store pages successfully evicted while session has history store cursor open': 0, 'forced eviction - pages evicted that were clean count': 0, 'forced eviction - pages evicted that were clean time (usecs)': 0, 'forced eviction - pages evicted that were dirty count': 0, 'forced eviction - pages evicted that were dirty time (usecs)': 0, 'forced eviction - pages selected because of a large number of updates to a single item': 0, 'forced eviction - pages selected because of too many deleted items count': 0, 'forced eviction - pages selected count': 0, 'forced eviction - pages selected unable to be evicted count': 0, 'forced eviction - pages selected unable to be evicted time': 0, 'hazard pointer blocked page eviction': 0, 'hazard pointer check calls': 0, 'hazard pointer check entries walked': 0, 'hazard pointer maximum array length': 0, 'history store score': 0, 'history store table insert calls': 0, 'history store table insert calls that returned restart': 0, 'history store table max on-disk size': 0, 'history store table on-disk size': 0, 'history store table out-of-order resolved updates that lose their durable timestamp': 0, 'history store table out-of-order updates that were fixed up by reinserting with the fixed timestamp': 0, 'history store table reads': 0, 'history store table reads missed': 0, 'history store table reads requiring squashed modifies': 0, 'history store table truncation by rollback to stable to remove an unstable update': 0, 'history store table truncation by rollback to stable to remove an update': 0, 'history store table truncation to remove an update': 0, 'history store table truncation to remove range of updates due to key being removed from the data page during reconciliation': 0, 'history store table truncation to remove range of updates due to out-of-order timestamp update on data page': 0, 'history store table writes requiring squashed modifies': 0, 'in-memory page passed criteria to be split': 0, 'in-memory page splits': 0, 'internal pages evicted': 0, 'internal pages queued for eviction': 0, 'internal pages seen by eviction walk': 0, 'internal pages seen by eviction walk that are already queued': 0, 'internal pages split during eviction': 0, 'leaf pages split during eviction': 0, 'maximum bytes configured': 6267338752.0, 'maximum milliseconds spent at a single eviction': 0, 'maximum page size seen at eviction': 0, 'modified pages evicted': 0, 'modified pages evicted by application threads': 0, 'operations timed out waiting for space in cache': 0, 'overflow pages read into cache': 0, 'page split during eviction deepened the tree': 0, 'page written requiring history store records': 0, 'pages currently held in the cache': 18, 'pages evicted by application threads': 0, 'pages evicted in parallel with checkpoint': 0, 'pages queued for eviction': 0, 'pages queued for eviction post lru sorting': 0, 'pages queued for urgent eviction': 0, 'pages queued for urgent eviction during walk': 0, 'pages queued for urgent eviction from history store due to high dirty content': 0, 'pages read into cache': 0, 'pages read into cache after truncate': 7, 'pages read into cache after truncate in prepare state': 0, 'pages removed from the ordinary queue to be queued for urgent eviction': 0, 'pages requested from the cache': 238, 'pages seen by eviction walk': 0, 'pages seen by eviction walk that are already queued': 0, 'pages selected for eviction unable to be evicted': 0, 'pages selected for eviction unable to be evicted as the parent page has overflow items': 0, 'pages selected for eviction unable to be evicted because of active children on an internal page': 0, 'pages selected for eviction unable to be evicted because of failure in reconciliation': 0, 'pages selected for eviction unable to be evicted because of race between checkpoint and out of order timestamps handling': 0, 'pages walked for eviction': 0, 'pages written from cache': 0, 'pages written requiring in-memory restoration': 0, 'percentage overhead': 8, 'the number of times full update inserted to history store': 0, 'the number of times reverse modify inserted to history store': 0, 'total milliseconds spent inside reentrant history store evictions in a reconciliation': 0, 'tracked bytes belonging to internal pages in the cache': 2102, 'tracked bytes belonging to leaf pages in the cache': 31603, 'tracked dirty bytes in the cache': 31205, 'tracked dirty pages in the cache': 6, 'unmodified pages evicted': 0}, 'capacity': {'background fsync file handles considered': 0, 'background fsync file handles synced': 0, 'background fsync time (msecs)': 0, 'bytes read': 0, 'bytes written for checkpoint': 0, 'bytes written for eviction': 0, 'bytes written for log': 21760, 'bytes written total': 21760, 'threshold to call fsync': 0, 'time waiting due to total capacity (usecs)': 0, 'time waiting during checkpoint (usecs)': 0, 'time waiting during eviction (usecs)': 0, 'time waiting during logging (usecs)': 0, 'time waiting during read (usecs)': 0}, 'checkpoint-cleanup': {'pages added for eviction': 0, 'pages removed': 0, 'pages skipped during tree walk': 0, 'pages visited': 0}, 'connection': {'auto adjusting condition resets': 0, 'auto adjusting condition wait calls': 9, 'auto adjusting condition wait raced to update timeout and skipped updating': 0, 'detected system time went backwards': 0, 'files currently open': 14, 'hash bucket array size for data handles': 512, 'hash bucket array size general': 512, 'memory allocations': 3241, 'memory frees': 2345, 'memory re-allocations': 257, 'pthread mutex condition wait calls': 20, 'pthread mutex shared lock read-lock calls': 260, 'pthread mutex shared lock write-lock calls': 61, 'total fsync I/Os': 33, 'total read I/Os': 16, 'total write I/Os': 29}, 'cursor': {'Total number of entries skipped by cursor next calls': 0, 'Total number of entries skipped by cursor prev calls': 0, 'Total number of entries skipped to position the history store cursor': 0, 'Total number of times a search near has exited due to prefix config': 0, 'cached cursor count': 16, 'cursor bulk loaded cursor insert calls': 0, 'cursor close calls that result in cache': 30, 'cursor create calls': 65, 'cursor insert calls': 44, 'cursor insert key and value bytes': 22171, 'cursor modify calls': 0, 'cursor modify key and value bytes affected': 0, 'cursor modify value bytes modified': 0, 'cursor next calls': 32, 'cursor next calls that skip due to a globally visible history store tombstone': 0, 'cursor next calls that skip greater than or equal to 100 entries': 0, 'cursor next calls that skip less than 100 entries': 32, 'cursor operation restarted': 0, 'cursor prev calls': 5, 'cursor prev calls that skip due to a globally visible history store tombstone': 0, 'cursor prev calls that skip greater than or equal to 100 entries': 0, 'cursor prev calls that skip less than 100 entries': 5, 'cursor remove calls': 0, 'cursor remove key bytes removed': 0, 'cursor reserve calls': 0, 'cursor reset calls': 254, 'cursor search calls': 189, 'cursor search history store calls': 0, 'cursor search near calls': 5, 'cursor sweep buckets': 0, 'cursor sweep cursors closed': 0, 'cursor sweep cursors examined': 0, 'cursor sweeps': 0, 'cursor truncate calls': 0, 'cursor update calls': 0, 'cursor update key and value bytes': 0, 'cursor update value size change': 0, 'cursors reused from cache': 14, 'open cursor count': 6}, 'data-handle': {'connection data handle size': 440, 'connection data handles currently active': 21, 'connection sweep candidate became referenced': 0, 'connection sweep dhandles closed': 0, 'connection sweep dhandles removed from hash list': 0, 'connection sweep time-of-death sets': 0, 'connection sweeps': 0, 'connection sweeps skipped due to checkpoint gathering handles': 0, 'session dhandles swept': 0, 'session sweep attempts': 30}, 'lock': {'checkpoint lock acquisitions': 0, 'checkpoint lock application thread wait time (usecs)': 0, 'checkpoint lock internal thread wait time (usecs)': 0, 'dhandle lock application thread time waiting (usecs)': 0, 'dhandle lock internal thread time waiting (usecs)': 0, 'dhandle read lock acquisitions': 5, 'dhandle write lock acquisitions': 23, 'durable timestamp queue lock application thread time waiting (usecs)': 0, 'durable timestamp queue lock internal thread time waiting (usecs)': 0, 'durable timestamp queue read lock acquisitions': 0, 'durable timestamp queue write lock acquisitions': 0, 'metadata lock acquisitions': 0, 'metadata lock application thread wait time (usecs)': 0, 'metadata lock internal thread wait time (usecs)': 0, 'read timestamp queue lock application thread time waiting (usecs)': 0, 'read timestamp queue lock internal thread time waiting (usecs)': 0, 'read timestamp queue read lock acquisitions': 0, 'read timestamp queue write lock acquisitions': 0, 'schema lock acquisitions': 12, 'schema lock application thread wait time (usecs)': 0, 'schema lock internal thread wait time (usecs)': 0, 'table lock application thread time waiting for the table lock (usecs)': 0, 'table lock internal thread time waiting for the table lock (usecs)': 0, 'table read lock acquisitions': 0, 'table write lock acquisitions': 10, 'txn global lock application thread time waiting (usecs)': 0, 'txn global lock internal thread time waiting (usecs)': 0, 'txn global read lock acquisitions': 3, 'txn global write lock acquisitions': 4}, 'log': {'busy returns attempting to switch slots': 0, 'force archive time sleeping (usecs)': 0, 'log bytes of payload data': 17908, 'log bytes written': 21632, 'log files manually zero-filled': 0, 'log flush operations': 2, 'log force write operations': 4, 'log force write operations skipped': 2, 'log records compressed': 29, 'log records not compressed': 2, 'log records too small to compress': 33, 'log release advances write LSN': 11, 'log scan operations': 0, 'log scan records requiring two reads': 0, 'log server thread advances write LSN': 2, 'log server thread write LSN walk skipped': 1000, 'log sync operations': 13, 'log sync time duration (usecs)': 32896, 'log sync_dir operations': 1, 'log sync_dir time duration (usecs)': 3460, 'log write operations': 64, 'logging bytes consolidated': 21120, 'maximum log file size': 104857600, 'number of pre-allocated log files to create': 2, 'pre-allocated log files not ready and missed': 1, 'pre-allocated log files prepared': 2, 'pre-allocated log files used': 0, 'records processed by log scan': 0, 'slot close lost race': 0, 'slot close unbuffered waits': 0, 'slot closures': 13, 'slot join atomic update races': 0, 'slot join calls atomic updates raced': 0, 'slot join calls did not yield': 64, 'slot join calls found active slot closed': 0, 'slot join calls slept': 0, 'slot join calls yielded': 0, 'slot join found active slot closed': 0, 'slot joins yield time (usecs)': 0, 'slot transitions unable to find free slot': 0, 'slot unbuffered writes': 0, 'total in-memory size of compressed records': 22283, 'total log buffer size': 33554432, 'total size of compressed records': 15193, 'written slots coalesced': 0, 'yields waiting for previous log file close': 0}, 'perf': {'file system read latency histogram (bucket 1) - 10-49ms': 0, 'file system read latency histogram (bucket 2) - 50-99ms': 0, 'file system read latency histogram (bucket 3) - 100-249ms': 0, 'file system read latency histogram (bucket 4) - 250-499ms': 0, 'file system read latency histogram (bucket 5) - 500-999ms': 0, 'file system read latency histogram (bucket 6) - 1000ms+': 0, 'file system write latency histogram (bucket 1) - 10-49ms': 0, 'file system write latency histogram (bucket 2) - 50-99ms': 0, 'file system write latency histogram (bucket 3) - 100-249ms': 0, 'file system write latency histogram (bucket 4) - 250-499ms': 0, 'file system write latency histogram (bucket 5) - 500-999ms': 0, 'file system write latency histogram (bucket 6) - 1000ms+': 0, 'operation read latency histogram (bucket 1) - 100-249us': 0, 'operation read latency histogram (bucket 2) - 250-499us': 0, 'operation read latency histogram (bucket 3) - 500-999us': 0, 'operation read latency histogram (bucket 4) - 1000-9999us': 0, 'operation read latency histogram (bucket 5) - 10000us+': 0, 'operation write latency histogram (bucket 1) - 100-249us': 0, 'operation write latency histogram (bucket 2) - 250-499us': 0, 'operation write latency histogram (bucket 3) - 500-999us': 0, 'operation write latency histogram (bucket 4) - 1000-9999us': 0, 'operation write latency histogram (bucket 5) - 10000us+': 0}, 'reconciliation': {'approximate byte size of timestamps in pages written': 0, 'approximate byte size of transaction IDs in pages written': 0, 'fast-path pages deleted': 0, 'internal-page overflow keys': 0, 'leaf-page overflow keys': 0, 'maximum milliseconds spent in a reconciliation call': 0, 'maximum milliseconds spent in building a disk image in a reconciliation': 0, 'maximum milliseconds spent in moving updates to the history store in a reconciliation': 0, 'page reconciliation calls': 0, 'page reconciliation calls for eviction': 0, 'page reconciliation calls that resulted in values with prepared transaction metadata': 0, 'page reconciliation calls that resulted in values with timestamps': 0, 'page reconciliation calls that resulted in values with transaction ids': 0, 'pages deleted': 0, 'pages written including an aggregated newest start durable timestamp ': 0, 'pages written including an aggregated newest stop durable timestamp ': 0, 'pages written including an aggregated newest stop timestamp ': 0, 'pages written including an aggregated newest stop transaction ID': 0, 'pages written including an aggregated newest transaction ID ': 0, 'pages written including an aggregated oldest start timestamp ': 0, 'pages written including an aggregated prepare': 0, 'pages written including at least one prepare state': 0, 'pages written including at least one start durable timestamp': 0, 'pages written including at least one start timestamp': 0, 'pages written including at least one start transaction ID': 0, 'pages written including at least one stop durable timestamp': 0, 'pages written including at least one stop timestamp': 0, 'pages written including at least one stop transaction ID': 0, 'records written including a prepare state': 0, 'records written including a start durable timestamp': 0, 'records written including a start timestamp': 0, 'records written including a start transaction ID': 0, 'records written including a stop durable timestamp': 0, 'records written including a stop timestamp': 0, 'records written including a stop transaction ID': 0, 'split bytes currently awaiting free': 0, 'split objects currently awaiting free': 0}, 'session': {'attempts to remove a local object and the object is in use': 0, 'flush_tier operation calls': 0, 'local objects removed': 0, 'open session count': 15, 'session query timestamp calls': 0, 'table alter failed calls': 0, 'table alter successful calls': 0, 'table alter triggering checkpoint calls': 0, 'table alter unchanged and skipped': 0, 'table compact failed calls': 0, 'table compact failed calls due to cache pressure': 0, 'table compact running': 0, 'table compact skipped as process would not reduce file size': 0, 'table compact successful calls': 0, 'table compact timeout': 0, 'table create failed calls': 0, 'table create successful calls': 9, 'table drop failed calls': 0, 'table drop successful calls': 0, 'table rename failed calls': 0, 'table rename successful calls': 0, 'table salvage failed calls': 0, 'table salvage successful calls': 0, 'table truncate failed calls': 0, 'table truncate successful calls': 0, 'table verify failed calls': 0, 'table verify successful calls': 0, 'tiered operations dequeued and processed': 0, 'tiered operations scheduled': 0, 'tiered storage local retention time (secs)': 0}, 'thread-state': {'active filesystem fsync calls': 0, 'active filesystem read calls': 0, 'active filesystem write calls': 0}, 'thread-yield': {'application thread time evicting (usecs)': 0, 'application thread time waiting for cache (usecs)': 0, 'connection close blocked waiting for transaction state stabilization': 0, 'connection close yielded for lsm manager shutdown': 0, 'data handle lock yielded': 0, 'get reference for page index and slot time sleeping (usecs)': 0, 'page access yielded due to prepare state change': 0, 'page acquire busy blocked': 0, 'page acquire eviction blocked': 0, 'page acquire locked blocked': 0, 'page acquire read blocked': 0, 'page acquire time sleeping (usecs)': 0, 'page delete rollback time sleeping for state change (usecs)': 0, 'page reconciliation yielded due to child modification': 0}, 'transaction': {'Number of prepared updates': 0, 'Number of prepared updates committed': 0, 'Number of prepared updates repeated on the same key': 0, 'Number of prepared updates rolled back': 0, 'checkpoint has acquired a snapshot for its transaction': 0, 'oldest pinned transaction ID rolled back for eviction': 0, 'prepared transactions': 0, 'prepared transactions committed': 0, 'prepared transactions currently active': 0, 'prepared transactions rolled back': 0, 'prepared transactions rolled back and do not remove the history store entry': 0, 'prepared transactions rolled back and fix the history store entry with checkpoint reserved transaction id': 0, 'query timestamp calls': 2, 'race to read prepared update retry': 0, 'rollback to stable calls': 0, 'rollback to stable history store records with stop timestamps older than newer records': 0, 'rollback to stable inconsistent checkpoint': 0, 'rollback to stable keys removed': 0, 'rollback to stable keys restored': 0, 'rollback to stable pages visited': 0, 'rollback to stable restored tombstones from history store': 0, 'rollback to stable restored updates from history store': 0, 'rollback to stable skipping delete rle': 0, 'rollback to stable skipping stable rle': 0, 'rollback to stable sweeping history store keys': 0, 'rollback to stable tree walk skipping pages': 0, 'rollback to stable updates aborted': 0, 'rollback to stable updates removed from history store': 0, 'sessions scanned in each walk of concurrent sessions': 657, 'set timestamp calls': 0, 'set timestamp durable calls': 0, 'set timestamp durable updates': 0, 'set timestamp oldest calls': 0, 'set timestamp oldest updates': 0, 'set timestamp stable calls': 0, 'set timestamp stable updates': 0, 'transaction begins': 10, 'transaction checkpoint currently running': 0, 'transaction checkpoint currently running for history store file': 0, 'transaction checkpoint generation': 0, 'transaction checkpoint history store file duration (usecs)': 0, 'transaction checkpoint max time (msecs)': 0, 'transaction checkpoint min time (msecs)': 0, 'transaction checkpoint most recent duration for gathering all handles (usecs)': 0, 'transaction checkpoint most recent duration for gathering applied handles (usecs)': 0, 'transaction checkpoint most recent duration for gathering skipped handles (usecs)': 0, 'transaction checkpoint most recent handles applied': 0, 'transaction checkpoint most recent handles skipped': 0, 'transaction checkpoint most recent handles walked': 0, 'transaction checkpoint most recent time (msecs)': 0, 'transaction checkpoint prepare currently running': 0, 'transaction checkpoint prepare max time (msecs)': 0, 'transaction checkpoint prepare min time (msecs)': 0, 'transaction checkpoint prepare most recent time (msecs)': 0, 'transaction checkpoint prepare total time (msecs)': 0, 'transaction checkpoint scrub dirty target': 0, 'transaction checkpoint scrub time (msecs)': 0, 'transaction checkpoint stop timing stress active': 0, 'transaction checkpoint total time (msecs)': 0, 'transaction checkpoints': 0, 'transaction checkpoints due to obsolete pages': 0, 'transaction checkpoints skipped because database was clean': 0, 'transaction fsync calls for checkpoint after allocating the transaction ID': 0, 'transaction fsync duration for checkpoint after allocating the transaction ID (usecs)': 0, 'transaction range of IDs currently pinned': 10, 'transaction range of IDs currently pinned by a checkpoint': 0, 'transaction range of timestamps currently pinned': 0, 'transaction range of timestamps pinned by a checkpoint': 0, 'transaction range of timestamps pinned by the oldest active read timestamp': 0, 'transaction range of timestamps pinned by the oldest timestamp': 0, 'transaction read timestamp of the oldest active reader': 0, 'transaction rollback to stable currently running': 0, 'transaction walk of concurrent sessions': 45, 'transactions committed': 6, 'transactions rolled back': 4, 'update conflicts': 0}, 'concurrentTransactions': {'write': {'out': 0, 'available': 128, 'totalTickets': 128}, 'read': {'out': 0, 'available': 128, 'totalTickets': 128}}, 'snapshot-window-settings': {'cache pressure percentage threshold': 95, 'current cache pressure percentage': 0, 'total number of SnapshotTooOld errors': 0, 'max target available snapshots window size in seconds': 5, 'target available snapshots window size in seconds': 5, 'current available snapshots window size in seconds': 0, 'latest majority snapshot timestamp available': 'Jan  1 00:00:00:0', 'oldest majority snapshot timestamp available': 'Jan  1 00:00:00:0'}, 'oplog': {'visibility timestamp': Timestamp(0, 0)}}, 'mem': {'bits': 64, 'resident': 82, 'virtual': 1271, 'supported': True}, 'metrics': {'aggStageCounters': {'$_internalApplyOplogUpdate': 0, '$_internalInhibitOptimization': 0, '$_internalSplitPipeline': 0, '$addFields': 0, '$bucket': 0, '$bucketAuto': 0, '$changeStream': 0, '$collStats': 0, '$count': 0, '$currentOp': 0, '$documents': 0, '$facet': 0, '$geoNear': 0, '$graphLookup': 0, '$group': 0, '$indexStats': 0, '$limit': 0, '$listLocalSessions': 0, '$listSessions': 0, '$lookup': 0, '$match': 0, '$merge': 0, '$mergeCursors': 0, '$out': 0, '$planCacheStats': 0, '$project': 0, '$queue': 0, '$redact': 0, '$replaceRoot': 0, '$replaceWith': 0, '$sample': 0, '$set': 0, '$skip': 0, '$sort': 0, '$sortByCount': 0, '$unionWith': 0, '$unset': 0, '$unwind': 0}, 'commands': {'<UNKNOWN>': 0, '_addShard': {'failed': 0, 'total': 0}, '_cloneCollectionOptionsFromPrimaryShard': {'failed': 0, 'total': 0}, '_configsvrAddShard': {'failed': 0, 'total': 0}, '_configsvrAddShardToZone': {'failed': 0, 'total': 0}, '_configsvrBalancerCollectionStatus': {'failed': 0, 'total': 0}, '_configsvrBalancerStart': {'failed': 0, 'total': 0}, '_configsvrBalancerStatus': {'failed': 0, 'total': 0}, '_configsvrBalancerStop': {'failed': 0, 'total': 0}, '_configsvrClearJumboFlag': {'failed': 0, 'total': 0}, '_configsvrCommitChunkMerge': {'failed': 0, 'total': 0}, '_configsvrCommitChunkMigration': {'failed': 0, 'total': 0}, '_configsvrCommitChunkSplit': {'failed': 0, 'total': 0}, '_configsvrCommitChunksMerge': {'failed': 0, 'total': 0}, '_configsvrCommitMovePrimary': {'failed': 0, 'total': 0}, '_configsvrCreateCollection': {'failed': 0, 'total': 0}, '_configsvrCreateDatabase': {'failed': 0, 'total': 0}, '_configsvrDropCollection': {'failed': 0, 'total': 0}, '_configsvrDropDatabase': {'failed': 0, 'total': 0}, '_configsvrEnableSharding': {'failed': 0, 'total': 0}, '_configsvrEnsureChunkVersionIsGreaterThan': {'failed': 0, 'total': 0}, '_configsvrMoveChunk': {'failed': 0, 'total': 0}, '_configsvrMovePrimary': {'failed': 0, 'total': 0}, '_configsvrRefineCollectionShardKey': {'failed': 0, 'total': 0}, '_configsvrRemoveShard': {'failed': 0, 'total': 0}, '_configsvrRemoveShardFromZone': {'failed': 0, 'total': 0}, '_configsvrRepairShardedCollectionChunksHistory': {'failed': 0, 'total': 0}, '_configsvrShardCollection': {'failed': 0, 'total': 0}, '_configsvrUpdateZoneKeyRange': {'failed': 0, 'total': 0}, '_flushDatabaseCacheUpdates': {'failed': 0, 'total': 0}, '_flushRoutingTableCacheUpdates': {'failed': 0, 'total': 0}, '_getNextSessionMods': {'failed': 0, 'total': 0}, '_getUserCacheGeneration': {'failed': 0, 'total': 0}, '_isSelf': {'failed': 0, 'total': 0}, '_killOperations': {'failed': 0, 'total': 0}, '_mergeAuthzCollections': {'failed': 0, 'total': 0}, '_migrateClone': {'failed': 0, 'total': 0}, '_recvChunkAbort': {'failed': 0, 'total': 0}, '_recvChunkCommit': {'failed': 0, 'total': 0}, '_recvChunkStart': {'failed': 0, 'total': 0}, '_recvChunkStatus': {'failed': 0, 'total': 0}, '_shardsvrCloneCatalogData': {'failed': 0, 'total': 0}, '_shardsvrMovePrimary': {'failed': 0, 'total': 0}, '_shardsvrSetAllowMigrations': {'failed': 0, 'total': 0}, '_shardsvrShardCollection': {'failed': 0, 'total': 0}, '_transferMods': {'failed': 0, 'total': 0}, 'abortTransaction': {'failed': 0, 'total': 0}, 'aggregate': {'allowDiskUseTrue': 0, 'failed': 0, 'total': 0}, 'appendOplogNote': {'failed': 0, 'total': 0}, 'applyOps': {'failed': 0, 'total': 0}, 'authenticate': {'failed': 0, 'total': 0}, 'autoSplitVector': {'failed': 0, 'total': 0}, 'availableQueryOptions': {'failed': 0, 'total': 0}, 'buildInfo': {'failed': 0, 'total': 0}, 'checkShardingIndex': {'failed': 0, 'total': 0}, 'cleanupOrphaned': {'failed': 0, 'total': 0}, 'cloneCollectionAsCapped': {'failed': 0, 'total': 0}, 'collMod': {'failed': 0, 'total': 0, 'validator': {'failed': 0, 'jsonSchema': 0, 'total': 0}}, 'collStats': {'failed': 0, 'total': 0}, 'commitTransaction': {'failed': 0, 'total': 0}, 'compact': {'failed': 0, 'total': 0}, 'connPoolStats': {'failed': 0, 'total': 0}, 'connPoolSync': {'failed': 0, 'total': 0}, 'connectionStatus': {'failed': 0, 'total': 0}, 'convertToCapped': {'failed': 0, 'total': 0}, 'coordinateCommitTransaction': {'failed': 0, 'total': 0}, 'count': {'failed': 0, 'total': 0}, 'create': {'failed': 0, 'total': 0, 'validator': {'failed': 0, 'jsonSchema': 0, 'total': 0}}, 'createIndexes': {'failed': 0, 'total': 1}, 'createRole': {'failed': 0, 'total': 0}, 'createUser': {'failed': 0, 'total': 0}, 'currentOp': {'failed': 0, 'total': 0}, 'dataSize': {'failed': 0, 'total': 0}, 'dbCheck': {'failed': 0, 'total': 0}, 'dbHash': {'failed': 0, 'total': 0}, 'dbStats': {'failed': 0, 'total': 0}, 'delete': {'failed': 0, 'total': 0}, 'distinct': {'failed': 0, 'total': 0}, 'driverOIDTest': {'failed': 0, 'total': 0}, 'drop': {'failed': 0, 'total': 0}, 'dropAllRolesFromDatabase': {'failed': 0, 'total': 0}, 'dropAllUsersFromDatabase': {'failed': 0, 'total': 0}, 'dropConnections': {'failed': 0, 'total': 0}, 'dropDatabase': {'failed': 0, 'total': 0}, 'dropIndexes': {'failed': 0, 'total': 0}, 'dropRole': {'failed': 0, 'total': 0}, 'dropUser': {'failed': 0, 'total': 0}, 'endSessions': {'failed': 0, 'total': 0}, 'explain': {'failed': 0, 'total': 0}, 'features': {'failed': 0, 'total': 0}, 'filemd5': {'failed': 0, 'total': 0}, 'find': {'failed': 0, 'total': 1}, 'findAndModify': {'arrayFilters': 0, 'failed': 0, 'pipeline': 0, 'total': 0}, 'flushRouterConfig': {'failed': 0, 'total': 0}, 'fsync': {'failed': 0, 'total': 0}, 'fsyncUnlock': {'failed': 0, 'total': 0}, 'geoSearch': {'failed': 0, 'total': 0}, 'getCmdLineOpts': {'failed': 0, 'total': 0}, 'getDatabaseVersion': {'failed': 0, 'total': 0}, 'getDefaultRWConcern': {'failed': 0, 'total': 0}, 'getDiagnosticData': {'failed': 0, 'total': 0}, 'getLastError': {'failed': 0, 'total': 0}, 'getLog': {'failed': 0, 'total': 0}, 'getMore': {'failed': 0, 'total': 0}, 'getParameter': {'failed': 0, 'total': 0}, 'getShardMap': {'failed': 0, 'total': 0}, 'getShardVersion': {'failed': 0, 'total': 0}, 'getnonce': {'failed': 0, 'total': 0}, 'grantPrivilegesToRole': {'failed': 0, 'total': 0}, 'grantRolesToRole': {'failed': 0, 'total': 0}, 'grantRolesToUser': {'failed': 0, 'total': 0}, 'hello': {'failed': 0, 'total': 1}, 'hostInfo': {'failed': 0, 'total': 0}, 'insert': {'failed': 0, 'total': 0}, 'internalRenameIfOptionsAndIndexesMatch': {'failed': 0, 'total': 0}, 'invalidateUserCache': {'failed': 0, 'total': 0}, 'isMaster': {'failed': 0, 'total': 3}, 'killAllSessions': {'failed': 0, 'total': 0}, 'killAllSessionsByPattern': {'failed': 0, 'total': 0}, 'killCursors': {'failed': 0, 'total': 0}, 'killOp': {'failed': 0, 'total': 0}, 'killSessions': {'failed': 0, 'total': 0}, 'listCollections': {'failed': 0, 'total': 0}, 'listCommands': {'failed': 0, 'total': 0}, 'listDatabases': {'failed': 0, 'total': 1}, 'listIndexes': {'failed': 2, 'total': 2}, 'lockInfo': {'failed': 0, 'total': 0}, 'logRotate': {'failed': 0, 'total': 0}, 'logout': {'failed': 0, 'total': 0}, 'mapReduce': {'failed': 0, 'total': 0}, 'mapreduce': {'shardedfinish': {'failed': 0, 'total': 0}}, 'mergeChunks': {'failed': 0, 'total': 0}, 'moveChunk': {'failed': 0, 'total': 0}, 'ping': {'failed': 0, 'total': 0}, 'planCacheClear': {'failed': 0, 'total': 0}, 'planCacheClearFilters': {'failed': 0, 'total': 0}, 'planCacheListFilters': {'failed': 0, 'total': 0}, 'planCacheSetFilter': {'failed': 0, 'total': 0}, 'prepareTransaction': {'failed': 0, 'total': 0}, 'profile': {'failed': 0, 'total': 0}, 'reIndex': {'failed': 0, 'total': 0}, 'refreshSessions': {'failed': 0, 'total': 0}, 'renameCollection': {'failed': 0, 'total': 0}, 'replSetAbortPrimaryCatchUp': {'failed': 0, 'total': 0}, 'replSetFreeze': {'failed': 0, 'total': 0}, 'replSetGetConfig': {'failed': 0, 'total': 0}, 'replSetGetRBID': {'failed': 0, 'total': 0}, 'replSetGetStatus': {'failed': 0, 'total': 0}, 'replSetHeartbeat': {'failed': 0, 'total': 0}, 'replSetInitiate': {'failed': 0, 'total': 0}, 'replSetMaintenance': {'failed': 0, 'total': 0}, 'replSetReconfig': {'failed': 0, 'total': 0}, 'replSetRequestVotes': {'failed': 0, 'total': 0}, 'replSetResizeOplog': {'failed': 0, 'total': 0}, 'replSetStepDown': {'failed': 0, 'total': 0}, 'replSetStepDownWithForce': {'failed': 0, 'total': 0}, 'replSetStepUp': {'failed': 0, 'total': 0}, 'replSetSyncFrom': {'failed': 0, 'total': 0}, 'replSetUpdatePosition': {'failed': 0, 'total': 0}, 'resetError': {'failed': 0, 'total': 0}, 'revokePrivilegesFromRole': {'failed': 0, 'total': 0}, 'revokeRolesFromRole': {'failed': 0, 'total': 0}, 'revokeRolesFromUser': {'failed': 0, 'total': 0}, 'rolesInfo': {'failed': 0, 'total': 0}, 'saslContinue': {'failed': 0, 'total': 0}, 'saslStart': {'failed': 0, 'total': 0}, 'serverStatus': {'failed': 0, 'total': 1}, 'setDefaultRWConcern': {'failed': 0, 'total': 0}, 'setFeatureCompatibilityVersion': {'failed': 0, 'total': 0}, 'setIndexCommitQuorum': {'failed': 0, 'total': 0}, 'setParameter': {'failed': 0, 'total': 0}, 'setProfilingFilterGlobally': {'failed': 0, 'total': 0}, 'setShardVersion': {'failed': 0, 'total': 0}, 'shardConnPoolStats': {'failed': 0, 'total': 0}, 'shardingState': {'failed': 0, 'total': 0}, 'shutdown': {'failed': 0, 'total': 0}, 'splitChunk': {'failed': 0, 'total': 0}, 'splitVector': {'failed': 0, 'total': 0}, 'startRecordingTraffic': {'failed': 0, 'total': 0}, 'startSession': {'failed': 0, 'total': 0}, 'stopRecordingTraffic': {'failed': 0, 'total': 0}, 'top': {'failed': 0, 'total': 0}, 'unsetSharding': {'failed': 0, 'total': 0}, 'update': {'arrayFilters': 0, 'failed': 0, 'pipeline': 0, 'total': 0}, 'updateRole': {'failed': 0, 'total': 0}, 'updateUser': {'failed': 0, 'total': 0}, 'usersInfo': {'failed': 0, 'total': 0}, 'validate': {'failed': 0, 'total': 0}, 'voteCommitIndexBuild': {'failed': 0, 'total': 0}, 'waitForFailPoint': {'failed': 0, 'total': 0}, 'whatsmyuri': {'failed': 0, 'total': 0}}, 'cursor': {'timedOut': 0, 'open': {'noTimeout': 0, 'pinned': 0, 'total': 0}}, 'document': {'deleted': 0, 'inserted': 0, 'returned': 0, 'updated': 0}, 'getLastError': {'wtime': {'num': 0, 'totalMillis': 0}, 'wtimeouts': 0, 'default': {'unsatisfiable': 0, 'wtimeouts': 0}}, 'operation': {'scanAndOrder': 0, 'writeConflicts': 0}, 'operatorCounters': {'expressions': {'$_internalJsEmit': 0, '$_internalKeyStringValue': 0, '$abs': 0, '$acos': 0, '$acosh': 0, '$add': 0, '$allElementsTrue': 0, '$and': 0, '$anyElementTrue': 0, '$arrayElemAt': 0, '$arrayToObject': 0, '$asin': 0, '$asinh': 0, '$atan': 0, '$atan2': 0, '$atanh': 0, '$avg': 0, '$binarySize': 0, '$bsonSize': 0, '$ceil': 0, '$cmp': 0, '$concat': 0, '$concatArrays': 0, '$cond': 0, '$const': 0, '$convert': 0, '$cos': 0, '$cosh': 0, '$dateFromParts': 0, '$dateFromString': 0, '$dateToParts': 0, '$dateToString': 0, '$dayOfMonth': 0, '$dayOfWeek': 0, '$dayOfYear': 0, '$degreesToRadians': 0, '$divide': 0, '$eq': 0, '$exp': 0, '$filter': 0, '$first': 0, '$floor': 0, '$function': 0, '$gt': 0, '$gte': 0, '$hour': 0, '$ifNull': 0, '$in': 0, '$indexOfArray': 0, '$indexOfBytes': 0, '$indexOfCP': 0, '$isArray': 0, '$isNumber': 0, '$isoDayOfWeek': 0, '$isoWeek': 0, '$isoWeekYear': 0, '$last': 0, '$let': 0, '$literal': 0, '$ln': 0, '$log': 0, '$log10': 0, '$lt': 0, '$lte': 0, '$ltrim': 0, '$map': 0, '$max': 0, '$mergeObjects': 0, '$meta': 0, '$millisecond': 0, '$min': 0, '$minute': 0, '$mod': 0, '$month': 0, '$multiply': 0, '$ne': 0, '$not': 0, '$objectToArray': 0, '$or': 0, '$pow': 0, '$radiansToDegrees': 0, '$rand': 0, '$range': 0, '$reduce': 0, '$regexFind': 0, '$regexFindAll': 0, '$regexMatch': 0, '$replaceAll': 0, '$replaceOne': 0, '$reverseArray': 0, '$round': 0, '$rtrim': 0, '$second': 0, '$setDifference': 0, '$setEquals': 0, '$setIntersection': 0, '$setIsSubset': 0, '$setUnion': 0, '$sin': 0, '$sinh': 0, '$size': 0, '$slice': 0, '$split': 0, '$sqrt': 0, '$stdDevPop': 0, '$stdDevSamp': 0, '$strLenBytes': 0, '$strLenCP': 0, '$strcasecmp': 0, '$substr': 0, '$substrBytes': 0, '$substrCP': 0, '$subtract': 0, '$sum': 0, '$switch': 0, '$tan': 0, '$tanh': 0, '$toBool': 0, '$toDate': 0, '$toDecimal': 0, '$toDouble': 0, '$toHashedIndexKey': 0, '$toInt': 0, '$toLong': 0, '$toLower': 0, '$toObjectId': 0, '$toString': 0, '$toUpper': 0, '$trim': 0, '$trunc': 0, '$type': 0, '$week': 0, '$year': 0, '$zip': 0}, 'match': {'$all': 0, '$alwaysFalse': 0, '$alwaysTrue': 0, '$and': 0, '$bitsAllClear': 0, '$bitsAllSet': 0, '$bitsAnyClear': 0, '$bitsAnySet': 0, '$comment': 0, '$elemMatch': 0, '$eq': 0, '$exists': 0, '$expr': 0, '$geoIntersects': 0, '$geoWithin': 0, '$gt': 0, '$gte': 0, '$in': 0, '$jsonSchema': 0, '$lt': 0, '$lte': 0, '$mod': 0, '$ne': 0, '$near': 0, '$nearSphere': 0, '$nin': 0, '$nor': 0, '$not': 0, '$or': 0, '$regex': 0, '$sampleRate': 0, '$size': 0, '$text': 0, '$type': 0, '$where': 0}}, 'query': {'deleteManyCount': 0, 'planCacheTotalSizeEstimateBytes': 0, 'updateDeleteManyDocumentsMaxCount': 0, 'updateDeleteManyDocumentsTotalCount': 0, 'updateDeleteManyDurationMaxMs': 0, 'updateDeleteManyDurationTotalMs': 0, 'updateManyCount': 0, 'updateOneOpStyleBroadcastWithExactIDCount': 0, 'multiPlanner': {'classicCount': 0, 'classicMicros': 0, 'classicWorks': 0, 'histograms': {'classicMicros': [{'lowerBound': 0, 'count': 0}, {'lowerBound': 1024, 'count': 0}, {'lowerBound': 4096, 'count': 0}, {'lowerBound': 16384, 'count': 0}, {'lowerBound': 65536, 'count': 0}, {'lowerBound': 262144, 'count': 0}, {'lowerBound': 1048576, 'count': 0}, {'lowerBound': 4194304, 'count': 0}, {'lowerBound': 16777216, 'count': 0}, {'lowerBound': 67108864, 'count': 0}, {'lowerBound': 268435456, 'count': 0}, {'lowerBound': 1073741824, 'count': 0}], 'classicNumPlans': [{'lowerBound': 0, 'count': 0}, {'lowerBound': 2, 'count': 0}, {'lowerBound': 4, 'count': 0}, {'lowerBound': 8, 'count': 0}, {'lowerBound': 16, 'count': 0}, {'lowerBound': 32, 'count': 0}], 'classicWorks': [{'lowerBound': 0, 'count': 0}, {'lowerBound': 128, 'count': 0}, {'lowerBound': 256, 'count': 0}, {'lowerBound': 512, 'count': 0}, {'lowerBound': 1024, 'count': 0}, {'lowerBound': 2048, 'count': 0}, {'lowerBound': 4096, 'count': 0}, {'lowerBound': 8192, 'count': 0}, {'lowerBound': 16384, 'count': 0}, {'lowerBound': 32768, 'count': 0}]}}}, 'queryExecutor': {'scanned': 0, 'scannedObjects': 0, 'collectionScans': {'nonTailable': 0, 'total': 0}}, 'record': {'moves': 0}, 'repl': {'executor': {'pool': {'inProgressCount': 0}, 'queues': {'networkInProgress': 0, 'sleepers': 0}, 'unsignaledEvents': 0, 'shuttingDown': False, 'networkInterface': 'DEPRECATED: getDiagnosticString is deprecated in NetworkInterfaceTL'}, 'apply': {'attemptsToBecomeSecondary': 0, 'batchSize': 0, 'batches': {'num': 0, 'totalMillis': 0}, 'ops': 0}, 'buffer': {'count': 0, 'maxSizeBytes': 0, 'sizeBytes': 0}, 'initialSync': {'completed': 0, 'failedAttempts': 0, 'failures': 0}, 'network': {'bytes': 0, 'getmores': {'num': 0, 'totalMillis': 0, 'numEmptyBatches': 0}, 'notPrimaryLegacyUnacknowledgedWrites': 0, 'notPrimaryUnacknowledgedWrites': 0, 'oplogGetMoresProcessed': {'num': 0, 'totalMillis': 0}, 'ops': 0, 'readersCreated': 0, 'replSetUpdatePosition': {'num': 0}}, 'stateTransition': {'lastStateTransition': '', 'userOperationsKilled': 0, 'userOperationsRunning': 0}, 'syncSource': {'numSelections': 0, 'numTimesChoseDifferent': 0, 'numTimesChoseSame': 0, 'numTimesCouldNotFind': 0}}, 'ttl': {'deletedDocuments': 0, 'passes': 0}}, 'ok': 1.0}\n",
            "Insert operation result: 678b1221c1c5f019fccc6b12\n",
            "Read operation result: {'_id': ObjectId('678b1221c1c5f019fccc6b12'), 'name': 'test', 'value': 123}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: build the Mongo shell command as a string\n",
        "query = \"\"\"\n",
        "db.chords.insert({\n",
        "  \"xml_id\": \"d13e1\",\n",
        "  \"dur\": \"8\",\n",
        "  \"dur_ppq\": \"12\",\n",
        "  \"stem_dir\": \"up\",\n",
        "  \"notes\": [\n",
        "    { \"xml_id\": \"d1e101\", \"pname\": \"c\", \"oct\": \"5\" },\n",
        "    { \"xml_id\": \"d1e118\", \"pname\": \"a\", \"oct\": \"4\" },\n",
        "    { \"xml_id\": \"d1e136\", \"pname\": \"c\", \"oct\": \"4\" }\n",
        "  ]\n",
        "});\n",
        "\n",
        "db.chords.insert({\n",
        "  \"xml_id\": \"d17e1\",\n",
        "  \"dur\": \"8\",\n",
        "  \"dur_ppq\": \"12\",\n",
        "  \"stem_dir\": \"up\",\n",
        "  \"notes\": [\n",
        "    { \"xml_id\": \"d1e157\", \"pname\": \"f\", \"oct\": \"3\" },\n",
        "    { \"xml_id\": \"d1e174\", \"pname\": \"f\", \"oct\": \"2\" }\n",
        "  ]\n",
        "});\n",
        "\"\"\"\n",
        "\n",
        "# Now execute the query string\n",
        "!mongo --quiet --eval '{query}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsphPfiQO4or",
        "outputId": "e7dbd83d-1d37-428a-ad2e-b7f27b17a5bf"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WriteResult({ \"nInserted\" : 1 })\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"db.chords.find().pretty()\"\"\"\n",
        "\n",
        "!mongo --quiet --eval '{query}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AkLf3UhcRPYe",
        "outputId": "8da6b153-5ee9-48f4-c9c5-ef499ff58b69"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "\t\"_id\" : ObjectId(\"678b139196bbc50009d06b71\"),\n",
            "\t\"xml:id\" : \"d13e1\",\n",
            "\t\"dur\" : \"8\",\n",
            "\t\"dur.ppq\" : \"12\",\n",
            "\t\"stem.dir\" : \"up\",\n",
            "\t\"notes\" : [\n",
            "\t\t{\n",
            "\t\t\t\"xml:id\" : \"d1e101\",\n",
            "\t\t\t\"pname\" : \"c\",\n",
            "\t\t\t\"oct\" : \"5\"\n",
            "\t\t},\n",
            "\t\t{\n",
            "\t\t\t\"xml:id\" : \"d1e118\",\n",
            "\t\t\t\"pname\" : \"a\",\n",
            "\t\t\t\"oct\" : \"4\"\n",
            "\t\t},\n",
            "\t\t{\n",
            "\t\t\t\"xml:id\" : \"d1e136\",\n",
            "\t\t\t\"pname\" : \"c\",\n",
            "\t\t\t\"oct\" : \"4\"\n",
            "\t\t}\n",
            "\t]\n",
            "}\n",
            "{\n",
            "\t\"_id\" : ObjectId(\"678b139196bbc50009d06b72\"),\n",
            "\t\"xml:id\" : \"d17e1\",\n",
            "\t\"dur\" : \"8\",\n",
            "\t\"dur.ppq\" : \"12\",\n",
            "\t\"stem.dir\" : \"up\",\n",
            "\t\"notes\" : [\n",
            "\t\t{\n",
            "\t\t\t\"xml:id\" : \"d1e157\",\n",
            "\t\t\t\"pname\" : \"f\",\n",
            "\t\t\t\"oct\" : \"3\"\n",
            "\t\t},\n",
            "\t\t{\n",
            "\t\t\t\"xml:id\" : \"d1e174\",\n",
            "\t\t\t\"pname\" : \"f\",\n",
            "\t\t\t\"oct\" : \"2\"\n",
            "\t\t}\n",
            "\t]\n",
            "}\n",
            "{\n",
            "\t\"_id\" : ObjectId(\"678b1a5fa95e3d7da9384ef0\"),\n",
            "\t\"xml_id\" : \"d13e1\",\n",
            "\t\"dur\" : \"8\",\n",
            "\t\"dur_ppq\" : \"12\",\n",
            "\t\"stem_dir\" : \"up\",\n",
            "\t\"notes\" : [\n",
            "\t\t{\n",
            "\t\t\t\"xml_id\" : \"d1e101\",\n",
            "\t\t\t\"pname\" : \"c\",\n",
            "\t\t\t\"oct\" : \"5\"\n",
            "\t\t},\n",
            "\t\t{\n",
            "\t\t\t\"xml_id\" : \"d1e118\",\n",
            "\t\t\t\"pname\" : \"a\",\n",
            "\t\t\t\"oct\" : \"4\"\n",
            "\t\t},\n",
            "\t\t{\n",
            "\t\t\t\"xml_id\" : \"d1e136\",\n",
            "\t\t\t\"pname\" : \"c\",\n",
            "\t\t\t\"oct\" : \"4\"\n",
            "\t\t}\n",
            "\t]\n",
            "}\n",
            "{\n",
            "\t\"_id\" : ObjectId(\"678b1a5fa95e3d7da9384ef1\"),\n",
            "\t\"xml_id\" : \"d17e1\",\n",
            "\t\"dur\" : \"8\",\n",
            "\t\"dur_ppq\" : \"12\",\n",
            "\t\"stem_dir\" : \"up\",\n",
            "\t\"notes\" : [\n",
            "\t\t{\n",
            "\t\t\t\"xml_id\" : \"d1e157\",\n",
            "\t\t\t\"pname\" : \"f\",\n",
            "\t\t\t\"oct\" : \"3\"\n",
            "\t\t},\n",
            "\t\t{\n",
            "\t\t\t\"xml_id\" : \"d1e174\",\n",
            "\t\t\t\"pname\" : \"f\",\n",
            "\t\t\t\"oct\" : \"2\"\n",
            "\t\t}\n",
            "\t]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we imagine the find command to get \"chords with upward stems that have 'f'\n",
        "# in one of their notes\"\n",
        "query = \"\"\"\n",
        "db.chords.find({\n",
        "  \"notes\": { \"$elemMatch\": { \"pname\": \"f\" } }\n",
        "}).pretty()\n",
        "\"\"\"\n",
        "\n",
        "!mongo --quiet --eval '{query}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VLK4-NtVQgri",
        "outputId": "c38fb355-c86d-4cd7-e17d-bb758ca78bd0"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "\t\"_id\" : ObjectId(\"678b139196bbc50009d06b72\"),\n",
            "\t\"xml:id\" : \"d17e1\",\n",
            "\t\"dur\" : \"8\",\n",
            "\t\"dur.ppq\" : \"12\",\n",
            "\t\"stem.dir\" : \"up\",\n",
            "\t\"notes\" : [\n",
            "\t\t{\n",
            "\t\t\t\"xml:id\" : \"d1e157\",\n",
            "\t\t\t\"pname\" : \"f\",\n",
            "\t\t\t\"oct\" : \"3\"\n",
            "\t\t},\n",
            "\t\t{\n",
            "\t\t\t\"xml:id\" : \"d1e174\",\n",
            "\t\t\t\"pname\" : \"f\",\n",
            "\t\t\t\"oct\" : \"2\"\n",
            "\t\t}\n",
            "\t]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"\n",
        "db.chords.find({ \"stem_dir\": \"up\" }).pretty()\n",
        "\"\"\"\n",
        "\n",
        "!mongo --quiet --eval '{query}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhN2JhNwT7sU",
        "outputId": "92f3eb04-b7bc-4efb-b907-a8089ad795c2"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "\t\"_id\" : ObjectId(\"678b1a5fa95e3d7da9384ef0\"),\n",
            "\t\"xml_id\" : \"d13e1\",\n",
            "\t\"dur\" : \"8\",\n",
            "\t\"dur_ppq\" : \"12\",\n",
            "\t\"stem_dir\" : \"up\",\n",
            "\t\"notes\" : [\n",
            "\t\t{\n",
            "\t\t\t\"xml_id\" : \"d1e101\",\n",
            "\t\t\t\"pname\" : \"c\",\n",
            "\t\t\t\"oct\" : \"5\"\n",
            "\t\t},\n",
            "\t\t{\n",
            "\t\t\t\"xml_id\" : \"d1e118\",\n",
            "\t\t\t\"pname\" : \"a\",\n",
            "\t\t\t\"oct\" : \"4\"\n",
            "\t\t},\n",
            "\t\t{\n",
            "\t\t\t\"xml_id\" : \"d1e136\",\n",
            "\t\t\t\"pname\" : \"c\",\n",
            "\t\t\t\"oct\" : \"4\"\n",
            "\t\t}\n",
            "\t]\n",
            "}\n",
            "{\n",
            "\t\"_id\" : ObjectId(\"678b1a5fa95e3d7da9384ef1\"),\n",
            "\t\"xml_id\" : \"d17e1\",\n",
            "\t\"dur\" : \"8\",\n",
            "\t\"dur_ppq\" : \"12\",\n",
            "\t\"stem_dir\" : \"up\",\n",
            "\t\"notes\" : [\n",
            "\t\t{\n",
            "\t\t\t\"xml_id\" : \"d1e157\",\n",
            "\t\t\t\"pname\" : \"f\",\n",
            "\t\t\t\"oct\" : \"3\"\n",
            "\t\t},\n",
            "\t\t{\n",
            "\t\t\t\"xml_id\" : \"d1e174\",\n",
            "\t\t\t\"pname\" : \"f\",\n",
            "\t\t\t\"oct\" : \"2\"\n",
            "\t\t}\n",
            "\t]\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3(d) - SPARQL and RDF Approach\n",
        "\n",
        "We have a scenario where we map chords to RDF.\n",
        "The question uses `rdfs:member ?note` to find chords with an F in them.\n",
        "\n",
        "**(i)** Why use `rdfs:member`?\n",
        "Because it is a standard, well-known property from the W3C RDF Schema,\n",
        "improving interoperability instead of inventing a new `mei:hasNotes` property.\n",
        "\n",
        "**(ii)** Some RDF for the first chord element in a chosen serialization (Turtle).\n",
        "We define a prefix `mei:`, plus any new concepts."
      ],
      "metadata": {
        "id": "seZtP96qP_V0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **rdflib + A Turtle Example for Q3(d)**"
      ],
      "metadata": {
        "id": "6EyuLz3DSo6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rdflib\n",
        "from rdflib import Graph, Namespace, Literal, RDF, URIRef\n",
        "from rdflib.namespace import FOAF, XSD\n",
        "\n",
        "print(\"rdflib installed.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTzGbTIaP92f",
        "outputId": "b35b4627-ebf7-4fef-bbce-bce6c0907f06"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: rdflib in /usr/local/lib/python3.11/dist-packages (7.1.2)\n",
            "Requirement already satisfied: pyparsing<4,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from rdflib) (3.2.1)\n",
            "rdflib installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile chord_data.ttl\n",
        "@prefix mei: <http://example.org/mei#> .\n",
        "@prefix xsd: <http://www.w3.org/2001/XMLSchema#> .\n",
        "\n",
        "<http://example.org/chord1> a mei:Chord ;\n",
        "    mei:stemDirection \"up\"^^xsd:string ;\n",
        "    mei:hasNote <http://example.org/note1> ,\n",
        "                <http://example.org/note2> .\n",
        "\n",
        "<http://example.org/note1> a mei:Note ;\n",
        "    mei:pname \"f\"^^xsd:string ;\n",
        "    mei:oct   \"5\"^^xsd:string .\n",
        "\n",
        "<http://example.org/note2> a mei:Note ;\n",
        "    mei:pname \"a\"^^xsd:string ;\n",
        "    mei:oct   \"5\"^^xsd:string ."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVokLy7hTOBm",
        "outputId": "2d0ded6c-194c-401e-f406-fb0dd7f5ffa3"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting chord_data.ttl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### **4.4 Load & SPARQL Query**\n",
        "g = Graph()\n",
        "g.parse(\"chord_data.ttl\", format=\"turtle\")\n",
        "\n",
        "print(\"Triples loaded:\", len(g))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCVz-9GATTQo",
        "outputId": "625946fe-fc2d-4fb3-eebd-dc4b7f940ed4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Triples loaded: 10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example SPARQL: find chords with stemDirection = \"up\" that have a note with pname=\"f\"\n",
        "q = \"\"\"\n",
        "PREFIX mei: <http://example.org/mei#>\n",
        "SELECT ?chord\n",
        "WHERE {\n",
        "  ?chord a mei:Chord .\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "res = g.query(q)\n",
        "for row in res:\n",
        "    print(\"Chord found:\", row.chord)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1cdu_GuUtQN",
        "outputId": "e97fba2b-8ba0-4a21-df60-def9ef4e62dd"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chord found: http://example.org/chord1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KX-c8X5oWGfD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}