{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNAUXTLTBoINJloa5o9e1pc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sreent/data-management-intro/blob/main/Lectures/CM3010%20MCQ%20September%202022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 1: Question (d) – XML & XPath"
      ],
      "metadata": {
        "id": "D-wOu0YJkZex"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Context\n",
        "The question: “Given this snippet, how many results does the XPath\n",
        "`//disk[@xml:id=\"1847336\"]/track[@duration>150]/*` select?”\n",
        "\n",
        "We’ll parse the snippet, run that XPath, and see the count of matched nodes."
      ],
      "metadata": {
        "id": "wzL_oyB_kb9_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install & Parse XML with `lxml`"
      ],
      "metadata": {
        "id": "7uksV7vlkf_X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lxml\n",
        "\n",
        "from lxml import etree\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "xml_data = \"\"\"\n",
        "<collection>\n",
        "  <disk xml:id=\"d1847336\">\n",
        "    <title>The Greatest Hits Ever: Volume 123</title>\n",
        "    <tracks>\n",
        "      <track no=\"1\" duration=\"193\">\n",
        "        <title>What is wrong with parsley?</title>\n",
        "        <artist>Herbal Reasoning</artist>\n",
        "      </track>\n",
        "      <track no=\"2\" duration=\"167\">\n",
        "        <title>Love threw me a googly</title>\n",
        "        <artist>Botham and the Fielders</artist>\n",
        "      </track>\n",
        "      <track no=\"3\" duration=\"121\">\n",
        "        <title>Comedy farm</title>\n",
        "        <artist>Just weird</artist>\n",
        "      </track>\n",
        "    </tracks>\n",
        "  </disk>\n",
        "</collection>\n",
        "\"\"\"\n",
        "\n",
        "root = etree.fromstring(xml_data)\n",
        "print(\"Parsed root tag:\", root.tag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4JCA82y_kZ7x",
        "outputId": "53cbb508-cd23-4a66-ca67-c7d7c050777c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (5.3.0)\n",
            "Parsed root tag: collection\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Running the XPath Query\n"
      ],
      "metadata": {
        "id": "BmPT927Zky98"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xp_expr = '//disk[xml:id=\"d1847336\"]/track[@duration>150]'\n",
        "nodes = root.xpath(xp_expr)\n",
        "\n",
        "print(\"Number of matched nodes:\", len(nodes))\n",
        "for i,node in enumerate(nodes, start=1):\n",
        "    snippet = etree.tostring(node, pretty_print=True, encoding='unicode').strip()\n",
        "    print(f\"Match {i}:\\n{snippet}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXp3tVuXkvGc",
        "outputId": "8e78c627-7e97-4e5e-b314-7815a3fe1a42"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of matched nodes: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Explanation:** We expect 2 tracks (duration=193, 167) each with 2 children (`<title>`, `<artist>`), so total 4."
      ],
      "metadata": {
        "id": "4Cb6oJ7xkyH2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 2: Question (h) – SQL Joins for “Shug Avery”"
      ],
      "metadata": {
        "id": "txd4r5bpGm6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Context\n",
        "We want to find staff members (Employees) who have had interactions\n",
        "with a client named “Shug Avery.” The exam question asks, “How might\n",
        "the query continue?” and shows multiple join approaches.\n",
        "\n",
        "Below, we’ll create a small MySQL DB with tables: `Client`, `Employee`, `Meeting`,\n",
        "and sample data. Then we can attempt different FROM/JOIN/WHERE styles."
      ],
      "metadata": {
        "id": "NDrCt-WAGq30"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install & Setup MySQL"
      ],
      "metadata": {
        "id": "9CNNwpQwGu-m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) MySQL installation (on Colab or Debian/Ubuntu)\n",
        "!apt -qq update > /dev/null\n",
        "!apt -y -qq install mysql-server > /dev/null\n",
        "!service mysql start\n",
        "\n",
        "# 2) Create user & DB\n",
        "!mysql -e \"CREATE USER IF NOT EXISTS 'examuser'@'localhost' IDENTIFIED BY 'exampass';\"\n",
        "!mysql -e \"CREATE DATABASE IF NOT EXISTS question_h_db;\"\n",
        "!mysql -e \"GRANT ALL PRIVILEGES ON question_h_db.* TO 'examuser'@'localhost';\"\n",
        "\n",
        "# 3) Python libs for SQL magic\n",
        "!pip install -q sqlalchemy==2.0.20 ipython-sql==0.5.0 pymysql==1.1.0\n",
        "%reload_ext sql\n",
        "\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', 10)\n",
        "\n",
        "# 4) Connect\n",
        "%sql mysql+pymysql://examuser:exampass@localhost/question_h_db\n",
        "\n",
        "print(\"MySQL ready for question (h) scenario.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uIowE3MlLmx",
        "outputId": "9a2793a9-e763-4db4-ac92-1dd7a6186294"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "\n",
            "WARNING: apt does not have a stable CLI interface. Use with caution in scripts.\n",
            "\n",
            " * Starting MySQL database server mysqld\n",
            "su: warning: cannot change directory to /nonexistent: No such file or directory\n",
            "   ...done.\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hMySQL ready for question (h) scenario.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Tables & Insert Sample Data"
      ],
      "metadata": {
        "id": "JCkwVWSJHAKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n",
        "DROP TABLE IF EXISTS Meeting;\n",
        "DROP TABLE IF EXISTS Employee;\n",
        "DROP TABLE IF EXISTS Client;\n",
        "\n",
        "CREATE TABLE Client (\n",
        "  ClientID INT PRIMARY KEY AUTO_INCREMENT,\n",
        "  givenName VARCHAR(100),\n",
        "  familyName VARCHAR(100)\n",
        ");\n",
        "\n",
        "CREATE TABLE Employee (\n",
        "  EmployeeID INT PRIMARY KEY AUTO_INCREMENT,\n",
        "  givenName VARCHAR(100),\n",
        "  familyName VARCHAR(100)\n",
        ");\n",
        "\n",
        "CREATE TABLE Meeting (\n",
        "  ID INT PRIMARY KEY AUTO_INCREMENT,\n",
        "  ClientID INT,\n",
        "  EmployeeID INT,\n",
        "  FOREIGN KEY (ClientID) REFERENCES Client(ClientID),\n",
        "  FOREIGN KEY (EmployeeID) REFERENCES Employee(EmployeeID)\n",
        ");\n",
        "\n",
        "INSERT INTO Client (givenName, familyName) VALUES\n",
        "('Shug', 'Avery'),\n",
        "('Sam', 'Adams'),\n",
        "('Jane', 'Doe');\n",
        "\n",
        "INSERT INTO Employee (givenName, familyName) VALUES\n",
        "('Alice', 'Smith'),\n",
        "('Bob', 'Marley');\n",
        "\n",
        "-- Some Meeting records\n",
        "INSERT INTO Meeting (ClientID, EmployeeID) VALUES\n",
        "(1,1),  -- Shug Avery with Alice Smith\n",
        "(1,2),  -- Shug Avery with Bob Marley\n",
        "(2,1),  -- Sam Adams with Alice Smith\n",
        "(3,2);  -- Jane Doe with Bob Marley"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfWyhNBoFDdU",
        "outputId": "5988b113-0bb1-4afd-ba6f-c86992f1f032"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * mysql+pymysql://examuser:***@localhost/question_h_db\n",
            "0 rows affected.\n",
            "0 rows affected.\n",
            "0 rows affected.\n",
            "0 rows affected.\n",
            "0 rows affected.\n",
            "0 rows affected.\n",
            "3 rows affected.\n",
            "2 rows affected.\n",
            "4 rows affected.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Queries for “Shug Avery”"
      ],
      "metadata": {
        "id": "eqAZU-ouG_Pw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%sql\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifsXtubYHaJy",
        "outputId": "0e3e354e-7dc1-4e77-910c-1ae995c7ae68"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "UsageError: %%sql is a cell magic, but the cell body is empty. Did you mean the line magic %sql (single %)?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 3: Question (i) – MongoDB Actors Born Before 1957"
      ],
      "metadata": {
        "id": "vtlPpWK9Hgky"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Context\n",
        "We want to see which query is correct for dateOfBirth < ISODate(\"1957-01-01\")."
      ],
      "metadata": {
        "id": "UqUwSH5cHpP-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Setup & Insert Data in MongoDB"
      ],
      "metadata": {
        "id": "G7n9K24hH44H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install MongoDB's dependencies\n",
        "!sudo wget http://archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1f-1ubuntu2_amd64.deb\n",
        "!sudo dpkg -i libssl1.1_1.1.1f-1ubuntu2_amd64.deb\n",
        "\n",
        "# Import the public key used by the package management system\n",
        "!wget -qO - https://www.mongodb.org/static/pgp/server-4.4.asc | apt-key add -\n",
        "\n",
        "# Create a list file for MongoDB\n",
        "!echo \"deb [ arch=amd64,arm64 ] http://repo.mongodb.org/apt/ubuntu bionic/mongodb-org/4.4 multiverse\" | tee /etc/apt/sources.list.d/mongodb-org-4.4.list\n",
        "\n",
        "# Reload the local package database\n",
        "!apt-get update > /dev/null\n",
        "\n",
        "# Install the MongoDB packages\n",
        "!apt-get install -y mongodb-org > /dev/null\n",
        "\n",
        "# Install pymongo\n",
        "!pip install -q pymongo\n",
        "\n",
        "# Create Data Folder\n",
        "!mkdir -p /data/db\n",
        "\n",
        "# Start MongoDB\n",
        "!mongod --fork --logpath /var/log/mongodb.log --dbpath /data/db\n",
        "\n",
        "from pymongo import MongoClient\n",
        "\n",
        "# Establish connection to MongoDB\n",
        "try:\n",
        "    client = MongoClient('localhost', 27017)\n",
        "    print(\"Connected to MongoDB\")\n",
        "except Exception as e:\n",
        "    print(\"Error connecting to MongoDB: \", e)\n",
        "    exit()\n",
        "\n",
        "# List databases to check the connection\n",
        "try:\n",
        "    databases = client.list_database_names()\n",
        "    print(\"Databases:\", databases)\n",
        "except Exception as e:\n",
        "    print(\"Error listing databases: \", e)\n",
        "\n",
        "# Retrieve server status\n",
        "try:\n",
        "    server_status = client.admin.command(\"serverStatus\")\n",
        "    print(\"Server Status:\", server_status)\n",
        "except Exception as e:\n",
        "    print(\"Error retrieving server status: \", e)\n",
        "\n",
        "# Perform basic database operations (Create, Read)\n",
        "try:\n",
        "    db = client.test_db\n",
        "    collection = db.test_collection\n",
        "    # Insert a document\n",
        "    insert_result = collection.insert_one({\"name\": \"test\", \"value\": 123})\n",
        "    print(\"Insert operation result:\", insert_result.inserted_id)\n",
        "    # Read a document\n",
        "    read_result = collection.find_one({\"name\": \"test\"})\n",
        "    print(\"Read operation result:\", read_result)\n",
        "except Exception as e:\n",
        "    print(\"Error performing database operations: \", e)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A50vJFU8HbhY",
        "outputId": "dfb555b9-d57a-4081-b25f-0c87a7f6a081"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-02-08 01:17:13--  http://archive.ubuntu.com/ubuntu/pool/main/o/openssl/libssl1.1_1.1.1f-1ubuntu2_amd64.deb\n",
            "Resolving archive.ubuntu.com (archive.ubuntu.com)... 185.125.190.81, 91.189.91.81, 185.125.190.83, ...\n",
            "Connecting to archive.ubuntu.com (archive.ubuntu.com)|185.125.190.81|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1318204 (1.3M) [application/vnd.debian.binary-package]\n",
            "Saving to: ‘libssl1.1_1.1.1f-1ubuntu2_amd64.deb’\n",
            "\n",
            "\r          libssl1.1   0%[                    ]       0  --.-KB/s               \rlibssl1.1_1.1.1f-1u 100%[===================>]   1.26M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-02-08 01:17:13 (17.7 MB/s) - ‘libssl1.1_1.1.1f-1ubuntu2_amd64.deb’ saved [1318204/1318204]\n",
            "\n",
            "Selecting previously unselected package libssl1.1:amd64.\n",
            "(Reading database ... 125458 files and directories currently installed.)\n",
            "Preparing to unpack libssl1.1_1.1.1f-1ubuntu2_amd64.deb ...\n",
            "Unpacking libssl1.1:amd64 (1.1.1f-1ubuntu2) ...\n",
            "Setting up libssl1.1:amd64 (1.1.1f-1ubuntu2) ...\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "Warning: apt-key is deprecated. Manage keyring files in trusted.gpg.d instead (see apt-key(8)).\n",
            "OK\n",
            "deb [ arch=amd64,arm64 ] http://repo.mongodb.org/apt/ubuntu bionic/mongodb-org/4.4 multiverse\n",
            "W: http://repo.mongodb.org/apt/ubuntu/dists/bionic/mongodb-org/4.4/InRelease: Key is stored in legacy trusted.gpg keyring (/etc/apt/trusted.gpg), see the DEPRECATION section in apt-key(8) for details.\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "about to fork child process, waiting until server is ready for connections.\n",
            "forked process: 7329\n",
            "child process started successfully, parent exiting\n",
            "Connected to MongoDB\n",
            "Databases: ['admin', 'config', 'local']\n",
            "Server Status: {'host': '0111b791904e', 'version': '4.4.29', 'process': 'mongod', 'pid': 7329, 'uptime': 1.0, 'uptimeMillis': 870, 'uptimeEstimate': 0, 'localTime': datetime.datetime(2025, 2, 8, 1, 17, 44, 737000), 'asserts': {'regular': 0, 'warning': 0, 'msg': 0, 'user': 4, 'rollovers': 0}, 'connections': {'current': 3, 'available': 838857, 'totalCreated': 3, 'active': 2, 'exhaustIsMaster': 0, 'exhaustHello': 0, 'awaitingTopologyChanges': 1}, 'electionMetrics': {'stepUpCmd': {'called': 0, 'successful': 0}, 'priorityTakeover': {'called': 0, 'successful': 0}, 'catchUpTakeover': {'called': 0, 'successful': 0}, 'electionTimeout': {'called': 0, 'successful': 0}, 'freezeTimeout': {'called': 0, 'successful': 0}, 'numStepDownsCausedByHigherTerm': 0, 'numCatchUps': 0, 'numCatchUpsSucceeded': 0, 'numCatchUpsAlreadyCaughtUp': 0, 'numCatchUpsSkipped': 0, 'numCatchUpsTimedOut': 0, 'numCatchUpsFailedWithError': 0, 'numCatchUpsFailedWithNewTerm': 0, 'numCatchUpsFailedWithReplSetAbortPrimaryCatchUpCmd': 0, 'averageCatchUpOps': 0.0}, 'extra_info': {'note': 'fields vary by platform', 'user_time_us': 646455, 'system_time_us': 60998, 'maximum_resident_set_kb': 84744, 'input_blocks': 0, 'output_blocks': 320, 'page_reclaims': 12484, 'page_faults': 0, 'voluntary_context_switches': 169, 'involuntary_context_switches': 203}, 'featureCompatibilityVersion': {'major': 4, 'minor': 4, 'transitioning': 0}, 'flowControl': {'enabled': True, 'targetRateLimit': 1000000000, 'timeAcquiringMicros': 2, 'locksPerKiloOp': 0.0, 'sustainerRate': 0, 'isLagged': False, 'isLaggedCount': 0, 'isLaggedTimeMicros': 0}, 'globalLock': {'totalTime': 894000, 'currentQueue': {'total': 0, 'readers': 0, 'writers': 0}, 'activeClients': {'total': 0, 'readers': 0, 'writers': 0}}, 'indexBulkBuilder': {'count': 0, 'filesOpenedForExternalSort': 0, 'filesClosedForExternalSort': 0}, 'locks': {'ParallelBatchWriterMode': {'acquireCount': {'r': 23}}, 'FeatureCompatibilityVersion': {'acquireCount': {'r': 16, 'w': 13}}, 'ReplicationStateTransition': {'acquireCount': {'w': 29}}, 'Global': {'acquireCount': {'r': 16, 'w': 9, 'W': 4}}, 'Database': {'acquireCount': {'r': 14, 'w': 3, 'W': 6}}, 'Collection': {'acquireCount': {'r': 20, 'w': 4, 'W': 2}}, 'Mutex': {'acquireCount': {'r': 24}}}, 'logicalSessionRecordCache': {'activeSessionsCount': 1, 'sessionsCollectionJobCount': 1, 'lastSessionsCollectionJobDurationMillis': 43, 'lastSessionsCollectionJobTimestamp': datetime.datetime(2025, 2, 8, 1, 17, 44, 684000), 'lastSessionsCollectionJobEntriesRefreshed': 0, 'lastSessionsCollectionJobEntriesEnded': 0, 'lastSessionsCollectionJobCursorsClosed': 0, 'transactionReaperJobCount': 1, 'lastTransactionReaperJobDurationMillis': 0, 'lastTransactionReaperJobTimestamp': datetime.datetime(2025, 2, 8, 1, 17, 44, 686000), 'lastTransactionReaperJobEntriesCleanedUp': 0, 'sessionCatalogSize': 0}, 'network': {'bytesIn': 960, 'bytesOut': 785, 'physicalBytesIn': 960, 'physicalBytesOut': 785, 'numSlowDNSOperations': 0, 'numSlowSSLOperations': 0, 'numRequests': 5, 'tcpFastOpen': {'kernelSetting': 1, 'serverSupported': True, 'clientSupported': True, 'accepted': 0}, 'compression': {'snappy': {'compressor': {'bytesIn': 0, 'bytesOut': 0}, 'decompressor': {'bytesIn': 0, 'bytesOut': 0}}, 'zstd': {'compressor': {'bytesIn': 0, 'bytesOut': 0}, 'decompressor': {'bytesIn': 0, 'bytesOut': 0}}, 'zlib': {'compressor': {'bytesIn': 0, 'bytesOut': 0}, 'decompressor': {'bytesIn': 0, 'bytesOut': 0}}}, 'serviceExecutorTaskStats': {'executor': 'passthrough', 'threadsRunning': 2}}, 'opLatencies': {'reads': {'latency': 0, 'ops': 0}, 'writes': {'latency': 0, 'ops': 0}, 'commands': {'latency': 341, 'ops': 3}, 'transactions': {'latency': 0, 'ops': 0}}, 'opReadConcernCounters': {'available': 0, 'linearizable': 0, 'local': 0, 'majority': 0, 'snapshot': 0, 'none': 1}, 'opcounters': {'insert': 0, 'query': 1, 'update': 0, 'delete': 0, 'getmore': 0, 'command': 8}, 'opcountersRepl': {'insert': 0, 'query': 0, 'update': 0, 'delete': 0, 'getmore': 0, 'command': 0}, 'scramCache': {'SCRAM-SHA-1': {'count': 0, 'hits': 0, 'misses': 0}, 'SCRAM-SHA-256': {'count': 0, 'hits': 0, 'misses': 0}}, 'security': {'authentication': {'mechanisms': {'MONGODB-X509': {'speculativeAuthenticate': {'received': 0, 'successful': 0}, 'authenticate': {'received': 0, 'successful': 0}}, 'SCRAM-SHA-1': {'speculativeAuthenticate': {'received': 0, 'successful': 0}, 'authenticate': {'received': 0, 'successful': 0}}, 'SCRAM-SHA-256': {'speculativeAuthenticate': {'received': 0, 'successful': 0}, 'authenticate': {'received': 0, 'successful': 0}}}}}, 'storageEngine': {'name': 'wiredTiger', 'supportsCommittedReads': True, 'oldestRequiredTimestampForCrashRecovery': Timestamp(0, 0), 'supportsPendingDrops': True, 'dropPendingIdents': 0, 'supportsTwoPhaseIndexBuild': True, 'supportsSnapshotReadConcern': True, 'readOnly': False, 'persistent': True, 'backupCursorOpen': False}, 'tcmalloc': {'generic': {'current_allocated_bytes': 89238952, 'heap_size': 90484736}, 'tcmalloc': {'pageheap_free_bytes': 557056, 'pageheap_unmapped_bytes': 0, 'max_total_thread_cache_bytes': 1073741824, 'current_total_thread_cache_bytes': 464600, 'total_free_bytes': 688728, 'central_cache_free_bytes': 207744, 'transfer_cache_free_bytes': 16384, 'thread_cache_free_bytes': 464600, 'aggressive_memory_decommit': 0, 'pageheap_committed_bytes': 90484736, 'pageheap_scavenge_count': 0, 'pageheap_commit_count': 52, 'pageheap_total_commit_bytes': 90484736, 'pageheap_decommit_count': 0, 'pageheap_total_decommit_bytes': 0, 'pageheap_reserve_count': 52, 'pageheap_total_reserve_bytes': 90484736, 'spinlock_total_delay_ns': 0, 'release_rate': 1.0, 'formattedString': '------------------------------------------------\\nMALLOC:       89239528 (   85.1 MiB) Bytes in use by application\\nMALLOC: +       557056 (    0.5 MiB) Bytes in page heap freelist\\nMALLOC: +       205440 (    0.2 MiB) Bytes in central cache freelist\\nMALLOC: +        16384 (    0.0 MiB) Bytes in transfer cache freelist\\nMALLOC: +       466328 (    0.4 MiB) Bytes in thread cache freelists\\nMALLOC: +      2752512 (    2.6 MiB) Bytes in malloc metadata\\nMALLOC:   ------------\\nMALLOC: =     93237248 (   88.9 MiB) Actual memory used (physical + swap)\\nMALLOC: +            0 (    0.0 MiB) Bytes released to OS (aka unmapped)\\nMALLOC:   ------------\\nMALLOC: =     93237248 (   88.9 MiB) Virtual address space used\\nMALLOC:\\nMALLOC:            659              Spans in use\\nMALLOC:             30              Thread heaps in use\\nMALLOC:           4096              Tcmalloc page size\\n------------------------------------------------\\nCall ReleaseFreeMemory() to release freelist memory to the OS (via madvise()).\\nBytes released to the OS take up virtual address space but no physical memory.\\n'}}, 'trafficRecording': {'running': False}, 'transactions': {'retriedCommandsCount': 0, 'retriedStatementsCount': 0, 'transactionsCollectionWriteCount': 0, 'currentActive': 0, 'currentInactive': 0, 'currentOpen': 0, 'totalAborted': 0, 'totalCommitted': 0, 'totalStarted': 0, 'totalPrepared': 0, 'totalPreparedThenCommitted': 0, 'totalPreparedThenAborted': 0, 'currentPrepared': 0}, 'transportSecurity': {'1.0': 0, '1.1': 0, '1.2': 0, '1.3': 0, 'unknown': 0}, 'twoPhaseCommitCoordinator': {'totalCreated': 0, 'totalStartedTwoPhaseCommit': 0, 'totalAbortedTwoPhaseCommit': 0, 'totalCommittedTwoPhaseCommit': 0, 'currentInSteps': {'writingParticipantList': 0, 'waitingForVotes': 0, 'writingDecision': 0, 'waitingForDecisionAcks': 0, 'deletingCoordinatorDoc': 0}}, 'wiredTiger': {'uri': 'statistics:', 'block-manager': {'blocks pre-loaded': 0, 'blocks read': 0, 'blocks written': 0, 'bytes read': 0, 'bytes read via memory map API': 0, 'bytes read via system call API': 0, 'bytes written': 0, 'bytes written for checkpoint': 0, 'bytes written via memory map API': 0, 'bytes written via system call API': 0, 'mapped blocks read': 0, 'mapped bytes read': 0, 'number of times the file was remapped because it changed size via fallocate or truncate': 0, 'number of times the region was remapped via write': 0}, 'cache': {'application threads page read from disk to cache count': 0, 'application threads page read from disk to cache time (usecs)': 0, 'application threads page write from cache to disk count': 0, 'application threads page write from cache to disk time (usecs)': 0, 'bytes allocated for updates': 30899, 'bytes belonging to page images in the cache': 0, 'bytes belonging to the history store table in the cache': 191, 'bytes currently in the cache': 33728, 'bytes dirty in the cache cumulative': 3832, 'bytes not belonging to page images in the cache': 33728, 'bytes read into cache': 0, 'bytes written from cache': 0, 'cache overflow score': 0, 'checkpoint blocked page eviction': 0, 'checkpoint of history store file blocked non-history store page eviction': 0, 'eviction calls to get a page': 0, 'eviction calls to get a page found queue empty': 0, 'eviction calls to get a page found queue empty after locking': 0, 'eviction currently operating in aggressive mode': 0, 'eviction empty score': 0, 'eviction gave up due to detecting an out of order on disk value behind the last update on the chain': 0, 'eviction gave up due to detecting an out of order tombstone ahead of the selected on disk update': 0, 'eviction gave up due to detecting an out of order tombstone ahead of the selected on disk update after validating the update chain': 0, 'eviction gave up due to detecting out of order timestamps on the update chain after the selected on disk update': 0, 'eviction passes of a file': 0, 'eviction server candidate queue empty when topping up': 0, 'eviction server candidate queue not empty when topping up': 0, 'eviction server evicting pages': 0, 'eviction server slept, because we did not make progress with eviction': 0, 'eviction server unable to reach eviction goal': 0, 'eviction server waiting for a leaf page': 10, 'eviction state': 64, 'eviction walk most recent sleeps for checkpoint handle gathering': 0, 'eviction walk target pages histogram - 0-9': 0, 'eviction walk target pages histogram - 10-31': 0, 'eviction walk target pages histogram - 128 and higher': 0, 'eviction walk target pages histogram - 32-63': 0, 'eviction walk target pages histogram - 64-128': 0, 'eviction walk target pages reduced due to history store cache pressure': 0, 'eviction walk target strategy both clean and dirty pages': 0, 'eviction walk target strategy only clean pages': 0, 'eviction walk target strategy only dirty pages': 0, 'eviction walks abandoned': 0, 'eviction walks gave up because they restarted their walk twice': 0, 'eviction walks gave up because they saw too many pages and found no candidates': 0, 'eviction walks gave up because they saw too many pages and found too few candidates': 0, 'eviction walks reached end of tree': 0, 'eviction walks restarted': 0, 'eviction walks started from root of tree': 0, 'eviction walks started from saved location in tree': 0, 'eviction worker thread active': 4, 'eviction worker thread created': 0, 'eviction worker thread evicting pages': 0, 'eviction worker thread removed': 0, 'eviction worker thread stable number': 0, 'files with active eviction walks': 0, 'files with new eviction walks started': 0, 'force re-tuning of eviction workers once in a while': 0, 'forced eviction - history store pages failed to evict while session has history store cursor open': 0, 'forced eviction - history store pages selected while session has history store cursor open': 0, 'forced eviction - history store pages successfully evicted while session has history store cursor open': 0, 'forced eviction - pages evicted that were clean count': 0, 'forced eviction - pages evicted that were clean time (usecs)': 0, 'forced eviction - pages evicted that were dirty count': 0, 'forced eviction - pages evicted that were dirty time (usecs)': 0, 'forced eviction - pages selected because of a large number of updates to a single item': 0, 'forced eviction - pages selected because of too many deleted items count': 0, 'forced eviction - pages selected count': 0, 'forced eviction - pages selected unable to be evicted count': 0, 'forced eviction - pages selected unable to be evicted time': 0, 'hazard pointer blocked page eviction': 0, 'hazard pointer check calls': 0, 'hazard pointer check entries walked': 0, 'hazard pointer maximum array length': 0, 'history store score': 0, 'history store table insert calls': 0, 'history store table insert calls that returned restart': 0, 'history store table max on-disk size': 0, 'history store table on-disk size': 0, 'history store table out-of-order resolved updates that lose their durable timestamp': 0, 'history store table out-of-order updates that were fixed up by reinserting with the fixed timestamp': 0, 'history store table reads': 0, 'history store table reads missed': 0, 'history store table reads requiring squashed modifies': 0, 'history store table truncation by rollback to stable to remove an unstable update': 0, 'history store table truncation by rollback to stable to remove an update': 0, 'history store table truncation to remove an update': 0, 'history store table truncation to remove range of updates due to key being removed from the data page during reconciliation': 0, 'history store table truncation to remove range of updates due to out-of-order timestamp update on data page': 0, 'history store table writes requiring squashed modifies': 0, 'in-memory page passed criteria to be split': 0, 'in-memory page splits': 0, 'internal pages evicted': 0, 'internal pages queued for eviction': 0, 'internal pages seen by eviction walk': 0, 'internal pages seen by eviction walk that are already queued': 0, 'internal pages split during eviction': 0, 'leaf pages split during eviction': 0, 'maximum bytes configured': 6267338752.0, 'maximum milliseconds spent at a single eviction': 0, 'maximum page size seen at eviction': 0, 'modified pages evicted': 0, 'modified pages evicted by application threads': 0, 'operations timed out waiting for space in cache': 0, 'overflow pages read into cache': 0, 'page split during eviction deepened the tree': 0, 'page written requiring history store records': 0, 'pages currently held in the cache': 18, 'pages evicted by application threads': 0, 'pages evicted in parallel with checkpoint': 0, 'pages queued for eviction': 0, 'pages queued for eviction post lru sorting': 0, 'pages queued for urgent eviction': 0, 'pages queued for urgent eviction during walk': 0, 'pages queued for urgent eviction from history store due to high dirty content': 0, 'pages read into cache': 0, 'pages read into cache after truncate': 7, 'pages read into cache after truncate in prepare state': 0, 'pages removed from the ordinary queue to be queued for urgent eviction': 0, 'pages requested from the cache': 238, 'pages seen by eviction walk': 0, 'pages seen by eviction walk that are already queued': 0, 'pages selected for eviction unable to be evicted': 0, 'pages selected for eviction unable to be evicted as the parent page has overflow items': 0, 'pages selected for eviction unable to be evicted because of active children on an internal page': 0, 'pages selected for eviction unable to be evicted because of failure in reconciliation': 0, 'pages selected for eviction unable to be evicted because of race between checkpoint and out of order timestamps handling': 0, 'pages walked for eviction': 0, 'pages written from cache': 0, 'pages written requiring in-memory restoration': 0, 'percentage overhead': 8, 'the number of times full update inserted to history store': 0, 'the number of times reverse modify inserted to history store': 0, 'total milliseconds spent inside reentrant history store evictions in a reconciliation': 0, 'tracked bytes belonging to internal pages in the cache': 2102, 'tracked bytes belonging to leaf pages in the cache': 31626, 'tracked dirty bytes in the cache': 31228, 'tracked dirty pages in the cache': 6, 'unmodified pages evicted': 0}, 'capacity': {'background fsync file handles considered': 0, 'background fsync file handles synced': 0, 'background fsync time (msecs)': 0, 'bytes read': 0, 'bytes written for checkpoint': 0, 'bytes written for eviction': 0, 'bytes written for log': 21120, 'bytes written total': 21120, 'threshold to call fsync': 0, 'time waiting due to total capacity (usecs)': 0, 'time waiting during checkpoint (usecs)': 0, 'time waiting during eviction (usecs)': 0, 'time waiting during logging (usecs)': 0, 'time waiting during read (usecs)': 0}, 'checkpoint-cleanup': {'pages added for eviction': 0, 'pages removed': 0, 'pages skipped during tree walk': 0, 'pages visited': 0}, 'connection': {'auto adjusting condition resets': 0, 'auto adjusting condition wait calls': 8, 'auto adjusting condition wait raced to update timeout and skipped updating': 0, 'detected system time went backwards': 0, 'files currently open': 14, 'hash bucket array size for data handles': 512, 'hash bucket array size general': 512, 'memory allocations': 3257, 'memory frees': 2347, 'memory re-allocations': 261, 'pthread mutex condition wait calls': 14, 'pthread mutex shared lock read-lock calls': 262, 'pthread mutex shared lock write-lock calls': 60, 'total fsync I/Os': 32, 'total read I/Os': 16, 'total write I/Os': 28}, 'cursor': {'Total number of entries skipped by cursor next calls': 0, 'Total number of entries skipped by cursor prev calls': 0, 'Total number of entries skipped to position the history store cursor': 0, 'Total number of times a search near has exited due to prefix config': 0, 'cached cursor count': 18, 'cursor bulk loaded cursor insert calls': 0, 'cursor close calls that result in cache': 27, 'cursor create calls': 67, 'cursor insert calls': 44, 'cursor insert key and value bytes': 22220, 'cursor modify calls': 0, 'cursor modify key and value bytes affected': 0, 'cursor modify value bytes modified': 0, 'cursor next calls': 32, 'cursor next calls that skip due to a globally visible history store tombstone': 0, 'cursor next calls that skip greater than or equal to 100 entries': 0, 'cursor next calls that skip less than 100 entries': 32, 'cursor operation restarted': 0, 'cursor prev calls': 5, 'cursor prev calls that skip due to a globally visible history store tombstone': 0, 'cursor prev calls that skip greater than or equal to 100 entries': 0, 'cursor prev calls that skip less than 100 entries': 5, 'cursor remove calls': 0, 'cursor remove key bytes removed': 0, 'cursor reserve calls': 0, 'cursor reset calls': 251, 'cursor search calls': 189, 'cursor search history store calls': 0, 'cursor search near calls': 5, 'cursor sweep buckets': 0, 'cursor sweep cursors closed': 0, 'cursor sweep cursors examined': 0, 'cursor sweeps': 0, 'cursor truncate calls': 0, 'cursor update calls': 0, 'cursor update key and value bytes': 0, 'cursor update value size change': 0, 'cursors reused from cache': 9, 'open cursor count': 6}, 'data-handle': {'connection data handle size': 440, 'connection data handles currently active': 21, 'connection sweep candidate became referenced': 0, 'connection sweep dhandles closed': 0, 'connection sweep dhandles removed from hash list': 0, 'connection sweep time-of-death sets': 0, 'connection sweeps': 0, 'connection sweeps skipped due to checkpoint gathering handles': 0, 'session dhandles swept': 0, 'session sweep attempts': 30}, 'lock': {'checkpoint lock acquisitions': 0, 'checkpoint lock application thread wait time (usecs)': 0, 'checkpoint lock internal thread wait time (usecs)': 0, 'dhandle lock application thread time waiting (usecs)': 0, 'dhandle lock internal thread time waiting (usecs)': 0, 'dhandle read lock acquisitions': 5, 'dhandle write lock acquisitions': 23, 'durable timestamp queue lock application thread time waiting (usecs)': 0, 'durable timestamp queue lock internal thread time waiting (usecs)': 0, 'durable timestamp queue read lock acquisitions': 0, 'durable timestamp queue write lock acquisitions': 0, 'metadata lock acquisitions': 0, 'metadata lock application thread wait time (usecs)': 0, 'metadata lock internal thread wait time (usecs)': 0, 'read timestamp queue lock application thread time waiting (usecs)': 0, 'read timestamp queue lock internal thread time waiting (usecs)': 0, 'read timestamp queue read lock acquisitions': 0, 'read timestamp queue write lock acquisitions': 0, 'schema lock acquisitions': 12, 'schema lock application thread wait time (usecs)': 0, 'schema lock internal thread wait time (usecs)': 0, 'table lock application thread time waiting for the table lock (usecs)': 0, 'table lock internal thread time waiting for the table lock (usecs)': 0, 'table read lock acquisitions': 0, 'table write lock acquisitions': 10, 'txn global lock application thread time waiting (usecs)': 0, 'txn global lock internal thread time waiting (usecs)': 0, 'txn global read lock acquisitions': 2, 'txn global write lock acquisitions': 3}, 'log': {'busy returns attempting to switch slots': 0, 'force archive time sleeping (usecs)': 0, 'log bytes of payload data': 17834, 'log bytes written': 21632, 'log files manually zero-filled': 0, 'log flush operations': 1, 'log force write operations': 2, 'log force write operations skipped': 1, 'log records compressed': 29, 'log records not compressed': 2, 'log records too small to compress': 33, 'log release advances write LSN': 11, 'log scan operations': 0, 'log scan records requiring two reads': 0, 'log server thread advances write LSN': 1, 'log server thread write LSN walk skipped': 1000, 'log sync operations': 12, 'log sync time duration (usecs)': 37769, 'log sync_dir operations': 1, 'log sync_dir time duration (usecs)': 3090, 'log write operations': 64, 'logging bytes consolidated': 20480, 'maximum log file size': 104857600, 'number of pre-allocated log files to create': 2, 'pre-allocated log files not ready and missed': 1, 'pre-allocated log files prepared': 2, 'pre-allocated log files used': 0, 'records processed by log scan': 0, 'slot close lost race': 0, 'slot close unbuffered waits': 0, 'slot closures': 12, 'slot join atomic update races': 0, 'slot join calls atomic updates raced': 0, 'slot join calls did not yield': 64, 'slot join calls found active slot closed': 0, 'slot join calls slept': 0, 'slot join calls yielded': 0, 'slot join found active slot closed': 0, 'slot joins yield time (usecs)': 0, 'slot transitions unable to find free slot': 0, 'slot unbuffered writes': 0, 'total in-memory size of compressed records': 22332, 'total log buffer size': 33554432, 'total size of compressed records': 15105, 'written slots coalesced': 0, 'yields waiting for previous log file close': 0}, 'perf': {'file system read latency histogram (bucket 1) - 10-49ms': 0, 'file system read latency histogram (bucket 2) - 50-99ms': 0, 'file system read latency histogram (bucket 3) - 100-249ms': 0, 'file system read latency histogram (bucket 4) - 250-499ms': 0, 'file system read latency histogram (bucket 5) - 500-999ms': 0, 'file system read latency histogram (bucket 6) - 1000ms+': 0, 'file system write latency histogram (bucket 1) - 10-49ms': 0, 'file system write latency histogram (bucket 2) - 50-99ms': 0, 'file system write latency histogram (bucket 3) - 100-249ms': 0, 'file system write latency histogram (bucket 4) - 250-499ms': 0, 'file system write latency histogram (bucket 5) - 500-999ms': 0, 'file system write latency histogram (bucket 6) - 1000ms+': 0, 'operation read latency histogram (bucket 1) - 100-249us': 0, 'operation read latency histogram (bucket 2) - 250-499us': 0, 'operation read latency histogram (bucket 3) - 500-999us': 0, 'operation read latency histogram (bucket 4) - 1000-9999us': 0, 'operation read latency histogram (bucket 5) - 10000us+': 0, 'operation write latency histogram (bucket 1) - 100-249us': 0, 'operation write latency histogram (bucket 2) - 250-499us': 0, 'operation write latency histogram (bucket 3) - 500-999us': 0, 'operation write latency histogram (bucket 4) - 1000-9999us': 0, 'operation write latency histogram (bucket 5) - 10000us+': 0}, 'reconciliation': {'approximate byte size of timestamps in pages written': 0, 'approximate byte size of transaction IDs in pages written': 0, 'fast-path pages deleted': 0, 'internal-page overflow keys': 0, 'leaf-page overflow keys': 0, 'maximum milliseconds spent in a reconciliation call': 0, 'maximum milliseconds spent in building a disk image in a reconciliation': 0, 'maximum milliseconds spent in moving updates to the history store in a reconciliation': 0, 'page reconciliation calls': 0, 'page reconciliation calls for eviction': 0, 'page reconciliation calls that resulted in values with prepared transaction metadata': 0, 'page reconciliation calls that resulted in values with timestamps': 0, 'page reconciliation calls that resulted in values with transaction ids': 0, 'pages deleted': 0, 'pages written including an aggregated newest start durable timestamp ': 0, 'pages written including an aggregated newest stop durable timestamp ': 0, 'pages written including an aggregated newest stop timestamp ': 0, 'pages written including an aggregated newest stop transaction ID': 0, 'pages written including an aggregated newest transaction ID ': 0, 'pages written including an aggregated oldest start timestamp ': 0, 'pages written including an aggregated prepare': 0, 'pages written including at least one prepare state': 0, 'pages written including at least one start durable timestamp': 0, 'pages written including at least one start timestamp': 0, 'pages written including at least one start transaction ID': 0, 'pages written including at least one stop durable timestamp': 0, 'pages written including at least one stop timestamp': 0, 'pages written including at least one stop transaction ID': 0, 'records written including a prepare state': 0, 'records written including a start durable timestamp': 0, 'records written including a start timestamp': 0, 'records written including a start transaction ID': 0, 'records written including a stop durable timestamp': 0, 'records written including a stop timestamp': 0, 'records written including a stop transaction ID': 0, 'split bytes currently awaiting free': 0, 'split objects currently awaiting free': 0}, 'session': {'attempts to remove a local object and the object is in use': 0, 'flush_tier operation calls': 0, 'local objects removed': 0, 'open session count': 15, 'session query timestamp calls': 0, 'table alter failed calls': 0, 'table alter successful calls': 0, 'table alter triggering checkpoint calls': 0, 'table alter unchanged and skipped': 0, 'table compact failed calls': 0, 'table compact failed calls due to cache pressure': 0, 'table compact running': 0, 'table compact skipped as process would not reduce file size': 0, 'table compact successful calls': 0, 'table compact timeout': 0, 'table create failed calls': 0, 'table create successful calls': 9, 'table drop failed calls': 0, 'table drop successful calls': 0, 'table rename failed calls': 0, 'table rename successful calls': 0, 'table salvage failed calls': 0, 'table salvage successful calls': 0, 'table truncate failed calls': 0, 'table truncate successful calls': 0, 'table verify failed calls': 0, 'table verify successful calls': 0, 'tiered operations dequeued and processed': 0, 'tiered operations scheduled': 0, 'tiered storage local retention time (secs)': 0}, 'thread-state': {'active filesystem fsync calls': 0, 'active filesystem read calls': 0, 'active filesystem write calls': 0}, 'thread-yield': {'application thread time evicting (usecs)': 0, 'application thread time waiting for cache (usecs)': 0, 'connection close blocked waiting for transaction state stabilization': 0, 'connection close yielded for lsm manager shutdown': 0, 'data handle lock yielded': 0, 'get reference for page index and slot time sleeping (usecs)': 0, 'page access yielded due to prepare state change': 0, 'page acquire busy blocked': 0, 'page acquire eviction blocked': 0, 'page acquire locked blocked': 0, 'page acquire read blocked': 0, 'page acquire time sleeping (usecs)': 0, 'page delete rollback time sleeping for state change (usecs)': 0, 'page reconciliation yielded due to child modification': 0}, 'transaction': {'Number of prepared updates': 0, 'Number of prepared updates committed': 0, 'Number of prepared updates repeated on the same key': 0, 'Number of prepared updates rolled back': 0, 'checkpoint has acquired a snapshot for its transaction': 0, 'oldest pinned transaction ID rolled back for eviction': 0, 'prepared transactions': 0, 'prepared transactions committed': 0, 'prepared transactions currently active': 0, 'prepared transactions rolled back': 0, 'prepared transactions rolled back and do not remove the history store entry': 0, 'prepared transactions rolled back and fix the history store entry with checkpoint reserved transaction id': 0, 'query timestamp calls': 3, 'race to read prepared update retry': 0, 'rollback to stable calls': 0, 'rollback to stable history store records with stop timestamps older than newer records': 0, 'rollback to stable inconsistent checkpoint': 0, 'rollback to stable keys removed': 0, 'rollback to stable keys restored': 0, 'rollback to stable pages visited': 0, 'rollback to stable restored tombstones from history store': 0, 'rollback to stable restored updates from history store': 0, 'rollback to stable skipping delete rle': 0, 'rollback to stable skipping stable rle': 0, 'rollback to stable sweeping history store keys': 0, 'rollback to stable tree walk skipping pages': 0, 'rollback to stable updates aborted': 0, 'rollback to stable updates removed from history store': 0, 'sessions scanned in each walk of concurrent sessions': 629, 'set timestamp calls': 0, 'set timestamp durable calls': 0, 'set timestamp durable updates': 0, 'set timestamp oldest calls': 0, 'set timestamp oldest updates': 0, 'set timestamp stable calls': 0, 'set timestamp stable updates': 0, 'transaction begins': 10, 'transaction checkpoint currently running': 0, 'transaction checkpoint currently running for history store file': 0, 'transaction checkpoint generation': 0, 'transaction checkpoint history store file duration (usecs)': 0, 'transaction checkpoint max time (msecs)': 0, 'transaction checkpoint min time (msecs)': 0, 'transaction checkpoint most recent duration for gathering all handles (usecs)': 0, 'transaction checkpoint most recent duration for gathering applied handles (usecs)': 0, 'transaction checkpoint most recent duration for gathering skipped handles (usecs)': 0, 'transaction checkpoint most recent handles applied': 0, 'transaction checkpoint most recent handles skipped': 0, 'transaction checkpoint most recent handles walked': 0, 'transaction checkpoint most recent time (msecs)': 0, 'transaction checkpoint prepare currently running': 0, 'transaction checkpoint prepare max time (msecs)': 0, 'transaction checkpoint prepare min time (msecs)': 0, 'transaction checkpoint prepare most recent time (msecs)': 0, 'transaction checkpoint prepare total time (msecs)': 0, 'transaction checkpoint scrub dirty target': 0, 'transaction checkpoint scrub time (msecs)': 0, 'transaction checkpoint stop timing stress active': 0, 'transaction checkpoint total time (msecs)': 0, 'transaction checkpoints': 0, 'transaction checkpoints due to obsolete pages': 0, 'transaction checkpoints skipped because database was clean': 0, 'transaction fsync calls for checkpoint after allocating the transaction ID': 0, 'transaction fsync duration for checkpoint after allocating the transaction ID (usecs)': 0, 'transaction range of IDs currently pinned': 10, 'transaction range of IDs currently pinned by a checkpoint': 0, 'transaction range of timestamps currently pinned': 0, 'transaction range of timestamps pinned by a checkpoint': 0, 'transaction range of timestamps pinned by the oldest active read timestamp': 0, 'transaction range of timestamps pinned by the oldest timestamp': 0, 'transaction read timestamp of the oldest active reader': 0, 'transaction rollback to stable currently running': 0, 'transaction walk of concurrent sessions': 43, 'transactions committed': 6, 'transactions rolled back': 4, 'update conflicts': 0}, 'concurrentTransactions': {'write': {'out': 0, 'available': 128, 'totalTickets': 128}, 'read': {'out': 0, 'available': 128, 'totalTickets': 128}}, 'snapshot-window-settings': {'cache pressure percentage threshold': 95, 'current cache pressure percentage': 0, 'total number of SnapshotTooOld errors': 0, 'max target available snapshots window size in seconds': 5, 'target available snapshots window size in seconds': 5, 'current available snapshots window size in seconds': 0, 'latest majority snapshot timestamp available': 'Jan  1 00:00:00:0', 'oldest majority snapshot timestamp available': 'Jan  1 00:00:00:0'}, 'oplog': {'visibility timestamp': Timestamp(0, 0)}}, 'mem': {'bits': 64, 'resident': 82, 'virtual': 1271, 'supported': True}, 'metrics': {'aggStageCounters': {'$_internalApplyOplogUpdate': 0, '$_internalInhibitOptimization': 0, '$_internalSplitPipeline': 0, '$addFields': 0, '$bucket': 0, '$bucketAuto': 0, '$changeStream': 0, '$collStats': 0, '$count': 0, '$currentOp': 0, '$documents': 0, '$facet': 0, '$geoNear': 0, '$graphLookup': 0, '$group': 0, '$indexStats': 0, '$limit': 0, '$listLocalSessions': 0, '$listSessions': 0, '$lookup': 0, '$match': 0, '$merge': 0, '$mergeCursors': 0, '$out': 0, '$planCacheStats': 0, '$project': 0, '$queue': 0, '$redact': 0, '$replaceRoot': 0, '$replaceWith': 0, '$sample': 0, '$set': 0, '$skip': 0, '$sort': 0, '$sortByCount': 0, '$unionWith': 0, '$unset': 0, '$unwind': 0}, 'commands': {'<UNKNOWN>': 0, '_addShard': {'failed': 0, 'total': 0}, '_cloneCollectionOptionsFromPrimaryShard': {'failed': 0, 'total': 0}, '_configsvrAddShard': {'failed': 0, 'total': 0}, '_configsvrAddShardToZone': {'failed': 0, 'total': 0}, '_configsvrBalancerCollectionStatus': {'failed': 0, 'total': 0}, '_configsvrBalancerStart': {'failed': 0, 'total': 0}, '_configsvrBalancerStatus': {'failed': 0, 'total': 0}, '_configsvrBalancerStop': {'failed': 0, 'total': 0}, '_configsvrClearJumboFlag': {'failed': 0, 'total': 0}, '_configsvrCommitChunkMerge': {'failed': 0, 'total': 0}, '_configsvrCommitChunkMigration': {'failed': 0, 'total': 0}, '_configsvrCommitChunkSplit': {'failed': 0, 'total': 0}, '_configsvrCommitChunksMerge': {'failed': 0, 'total': 0}, '_configsvrCommitMovePrimary': {'failed': 0, 'total': 0}, '_configsvrCreateCollection': {'failed': 0, 'total': 0}, '_configsvrCreateDatabase': {'failed': 0, 'total': 0}, '_configsvrDropCollection': {'failed': 0, 'total': 0}, '_configsvrDropDatabase': {'failed': 0, 'total': 0}, '_configsvrEnableSharding': {'failed': 0, 'total': 0}, '_configsvrEnsureChunkVersionIsGreaterThan': {'failed': 0, 'total': 0}, '_configsvrMoveChunk': {'failed': 0, 'total': 0}, '_configsvrMovePrimary': {'failed': 0, 'total': 0}, '_configsvrRefineCollectionShardKey': {'failed': 0, 'total': 0}, '_configsvrRemoveShard': {'failed': 0, 'total': 0}, '_configsvrRemoveShardFromZone': {'failed': 0, 'total': 0}, '_configsvrRepairShardedCollectionChunksHistory': {'failed': 0, 'total': 0}, '_configsvrShardCollection': {'failed': 0, 'total': 0}, '_configsvrUpdateZoneKeyRange': {'failed': 0, 'total': 0}, '_flushDatabaseCacheUpdates': {'failed': 0, 'total': 0}, '_flushRoutingTableCacheUpdates': {'failed': 0, 'total': 0}, '_getNextSessionMods': {'failed': 0, 'total': 0}, '_getUserCacheGeneration': {'failed': 0, 'total': 0}, '_isSelf': {'failed': 0, 'total': 0}, '_killOperations': {'failed': 0, 'total': 0}, '_mergeAuthzCollections': {'failed': 0, 'total': 0}, '_migrateClone': {'failed': 0, 'total': 0}, '_recvChunkAbort': {'failed': 0, 'total': 0}, '_recvChunkCommit': {'failed': 0, 'total': 0}, '_recvChunkStart': {'failed': 0, 'total': 0}, '_recvChunkStatus': {'failed': 0, 'total': 0}, '_shardsvrCloneCatalogData': {'failed': 0, 'total': 0}, '_shardsvrMovePrimary': {'failed': 0, 'total': 0}, '_shardsvrSetAllowMigrations': {'failed': 0, 'total': 0}, '_shardsvrShardCollection': {'failed': 0, 'total': 0}, '_transferMods': {'failed': 0, 'total': 0}, 'abortTransaction': {'failed': 0, 'total': 0}, 'aggregate': {'allowDiskUseTrue': 0, 'failed': 0, 'total': 0}, 'appendOplogNote': {'failed': 0, 'total': 0}, 'applyOps': {'failed': 0, 'total': 0}, 'authenticate': {'failed': 0, 'total': 0}, 'autoSplitVector': {'failed': 0, 'total': 0}, 'availableQueryOptions': {'failed': 0, 'total': 0}, 'buildInfo': {'failed': 0, 'total': 0}, 'checkShardingIndex': {'failed': 0, 'total': 0}, 'cleanupOrphaned': {'failed': 0, 'total': 0}, 'cloneCollectionAsCapped': {'failed': 0, 'total': 0}, 'collMod': {'failed': 0, 'total': 0, 'validator': {'failed': 0, 'jsonSchema': 0, 'total': 0}}, 'collStats': {'failed': 0, 'total': 0}, 'commitTransaction': {'failed': 0, 'total': 0}, 'compact': {'failed': 0, 'total': 0}, 'connPoolStats': {'failed': 0, 'total': 0}, 'connPoolSync': {'failed': 0, 'total': 0}, 'connectionStatus': {'failed': 0, 'total': 0}, 'convertToCapped': {'failed': 0, 'total': 0}, 'coordinateCommitTransaction': {'failed': 0, 'total': 0}, 'count': {'failed': 0, 'total': 0}, 'create': {'failed': 0, 'total': 0, 'validator': {'failed': 0, 'jsonSchema': 0, 'total': 0}}, 'createIndexes': {'failed': 0, 'total': 1}, 'createRole': {'failed': 0, 'total': 0}, 'createUser': {'failed': 0, 'total': 0}, 'currentOp': {'failed': 0, 'total': 0}, 'dataSize': {'failed': 0, 'total': 0}, 'dbCheck': {'failed': 0, 'total': 0}, 'dbHash': {'failed': 0, 'total': 0}, 'dbStats': {'failed': 0, 'total': 0}, 'delete': {'failed': 0, 'total': 0}, 'distinct': {'failed': 0, 'total': 0}, 'driverOIDTest': {'failed': 0, 'total': 0}, 'drop': {'failed': 0, 'total': 0}, 'dropAllRolesFromDatabase': {'failed': 0, 'total': 0}, 'dropAllUsersFromDatabase': {'failed': 0, 'total': 0}, 'dropConnections': {'failed': 0, 'total': 0}, 'dropDatabase': {'failed': 0, 'total': 0}, 'dropIndexes': {'failed': 0, 'total': 0}, 'dropRole': {'failed': 0, 'total': 0}, 'dropUser': {'failed': 0, 'total': 0}, 'endSessions': {'failed': 0, 'total': 0}, 'explain': {'failed': 0, 'total': 0}, 'features': {'failed': 0, 'total': 0}, 'filemd5': {'failed': 0, 'total': 0}, 'find': {'failed': 0, 'total': 1}, 'findAndModify': {'arrayFilters': 0, 'failed': 0, 'pipeline': 0, 'total': 0}, 'flushRouterConfig': {'failed': 0, 'total': 0}, 'fsync': {'failed': 0, 'total': 0}, 'fsyncUnlock': {'failed': 0, 'total': 0}, 'geoSearch': {'failed': 0, 'total': 0}, 'getCmdLineOpts': {'failed': 0, 'total': 0}, 'getDatabaseVersion': {'failed': 0, 'total': 0}, 'getDefaultRWConcern': {'failed': 0, 'total': 0}, 'getDiagnosticData': {'failed': 0, 'total': 0}, 'getLastError': {'failed': 0, 'total': 0}, 'getLog': {'failed': 0, 'total': 0}, 'getMore': {'failed': 0, 'total': 0}, 'getParameter': {'failed': 0, 'total': 0}, 'getShardMap': {'failed': 0, 'total': 0}, 'getShardVersion': {'failed': 0, 'total': 0}, 'getnonce': {'failed': 0, 'total': 0}, 'grantPrivilegesToRole': {'failed': 0, 'total': 0}, 'grantRolesToRole': {'failed': 0, 'total': 0}, 'grantRolesToUser': {'failed': 0, 'total': 0}, 'hello': {'failed': 0, 'total': 1}, 'hostInfo': {'failed': 0, 'total': 0}, 'insert': {'failed': 0, 'total': 0}, 'internalRenameIfOptionsAndIndexesMatch': {'failed': 0, 'total': 0}, 'invalidateUserCache': {'failed': 0, 'total': 0}, 'isMaster': {'failed': 0, 'total': 2}, 'killAllSessions': {'failed': 0, 'total': 0}, 'killAllSessionsByPattern': {'failed': 0, 'total': 0}, 'killCursors': {'failed': 0, 'total': 0}, 'killOp': {'failed': 0, 'total': 0}, 'killSessions': {'failed': 0, 'total': 0}, 'listCollections': {'failed': 0, 'total': 0}, 'listCommands': {'failed': 0, 'total': 0}, 'listDatabases': {'failed': 0, 'total': 1}, 'listIndexes': {'failed': 2, 'total': 2}, 'lockInfo': {'failed': 0, 'total': 0}, 'logRotate': {'failed': 0, 'total': 0}, 'logout': {'failed': 0, 'total': 0}, 'mapReduce': {'failed': 0, 'total': 0}, 'mapreduce': {'shardedfinish': {'failed': 0, 'total': 0}}, 'mergeChunks': {'failed': 0, 'total': 0}, 'moveChunk': {'failed': 0, 'total': 0}, 'ping': {'failed': 0, 'total': 0}, 'planCacheClear': {'failed': 0, 'total': 0}, 'planCacheClearFilters': {'failed': 0, 'total': 0}, 'planCacheListFilters': {'failed': 0, 'total': 0}, 'planCacheSetFilter': {'failed': 0, 'total': 0}, 'prepareTransaction': {'failed': 0, 'total': 0}, 'profile': {'failed': 0, 'total': 0}, 'reIndex': {'failed': 0, 'total': 0}, 'refreshSessions': {'failed': 0, 'total': 0}, 'renameCollection': {'failed': 0, 'total': 0}, 'replSetAbortPrimaryCatchUp': {'failed': 0, 'total': 0}, 'replSetFreeze': {'failed': 0, 'total': 0}, 'replSetGetConfig': {'failed': 0, 'total': 0}, 'replSetGetRBID': {'failed': 0, 'total': 0}, 'replSetGetStatus': {'failed': 0, 'total': 0}, 'replSetHeartbeat': {'failed': 0, 'total': 0}, 'replSetInitiate': {'failed': 0, 'total': 0}, 'replSetMaintenance': {'failed': 0, 'total': 0}, 'replSetReconfig': {'failed': 0, 'total': 0}, 'replSetRequestVotes': {'failed': 0, 'total': 0}, 'replSetResizeOplog': {'failed': 0, 'total': 0}, 'replSetStepDown': {'failed': 0, 'total': 0}, 'replSetStepDownWithForce': {'failed': 0, 'total': 0}, 'replSetStepUp': {'failed': 0, 'total': 0}, 'replSetSyncFrom': {'failed': 0, 'total': 0}, 'replSetUpdatePosition': {'failed': 0, 'total': 0}, 'resetError': {'failed': 0, 'total': 0}, 'revokePrivilegesFromRole': {'failed': 0, 'total': 0}, 'revokeRolesFromRole': {'failed': 0, 'total': 0}, 'revokeRolesFromUser': {'failed': 0, 'total': 0}, 'rolesInfo': {'failed': 0, 'total': 0}, 'saslContinue': {'failed': 0, 'total': 0}, 'saslStart': {'failed': 0, 'total': 0}, 'serverStatus': {'failed': 0, 'total': 1}, 'setDefaultRWConcern': {'failed': 0, 'total': 0}, 'setFeatureCompatibilityVersion': {'failed': 0, 'total': 0}, 'setIndexCommitQuorum': {'failed': 0, 'total': 0}, 'setParameter': {'failed': 0, 'total': 0}, 'setProfilingFilterGlobally': {'failed': 0, 'total': 0}, 'setShardVersion': {'failed': 0, 'total': 0}, 'shardConnPoolStats': {'failed': 0, 'total': 0}, 'shardingState': {'failed': 0, 'total': 0}, 'shutdown': {'failed': 0, 'total': 0}, 'splitChunk': {'failed': 0, 'total': 0}, 'splitVector': {'failed': 0, 'total': 0}, 'startRecordingTraffic': {'failed': 0, 'total': 0}, 'startSession': {'failed': 0, 'total': 0}, 'stopRecordingTraffic': {'failed': 0, 'total': 0}, 'top': {'failed': 0, 'total': 0}, 'unsetSharding': {'failed': 0, 'total': 0}, 'update': {'arrayFilters': 0, 'failed': 0, 'pipeline': 0, 'total': 0}, 'updateRole': {'failed': 0, 'total': 0}, 'updateUser': {'failed': 0, 'total': 0}, 'usersInfo': {'failed': 0, 'total': 0}, 'validate': {'failed': 0, 'total': 0}, 'voteCommitIndexBuild': {'failed': 0, 'total': 0}, 'waitForFailPoint': {'failed': 0, 'total': 0}, 'whatsmyuri': {'failed': 0, 'total': 0}}, 'cursor': {'timedOut': 0, 'open': {'noTimeout': 0, 'pinned': 0, 'total': 0}}, 'document': {'deleted': 0, 'inserted': 0, 'returned': 0, 'updated': 0}, 'getLastError': {'wtime': {'num': 0, 'totalMillis': 0}, 'wtimeouts': 0, 'default': {'unsatisfiable': 0, 'wtimeouts': 0}}, 'operation': {'scanAndOrder': 0, 'writeConflicts': 0}, 'operatorCounters': {'expressions': {'$_internalJsEmit': 0, '$_internalKeyStringValue': 0, '$abs': 0, '$acos': 0, '$acosh': 0, '$add': 0, '$allElementsTrue': 0, '$and': 0, '$anyElementTrue': 0, '$arrayElemAt': 0, '$arrayToObject': 0, '$asin': 0, '$asinh': 0, '$atan': 0, '$atan2': 0, '$atanh': 0, '$avg': 0, '$binarySize': 0, '$bsonSize': 0, '$ceil': 0, '$cmp': 0, '$concat': 0, '$concatArrays': 0, '$cond': 0, '$const': 0, '$convert': 0, '$cos': 0, '$cosh': 0, '$dateFromParts': 0, '$dateFromString': 0, '$dateToParts': 0, '$dateToString': 0, '$dayOfMonth': 0, '$dayOfWeek': 0, '$dayOfYear': 0, '$degreesToRadians': 0, '$divide': 0, '$eq': 0, '$exp': 0, '$filter': 0, '$first': 0, '$floor': 0, '$function': 0, '$gt': 0, '$gte': 0, '$hour': 0, '$ifNull': 0, '$in': 0, '$indexOfArray': 0, '$indexOfBytes': 0, '$indexOfCP': 0, '$isArray': 0, '$isNumber': 0, '$isoDayOfWeek': 0, '$isoWeek': 0, '$isoWeekYear': 0, '$last': 0, '$let': 0, '$literal': 0, '$ln': 0, '$log': 0, '$log10': 0, '$lt': 0, '$lte': 0, '$ltrim': 0, '$map': 0, '$max': 0, '$mergeObjects': 0, '$meta': 0, '$millisecond': 0, '$min': 0, '$minute': 0, '$mod': 0, '$month': 0, '$multiply': 0, '$ne': 0, '$not': 0, '$objectToArray': 0, '$or': 0, '$pow': 0, '$radiansToDegrees': 0, '$rand': 0, '$range': 0, '$reduce': 0, '$regexFind': 0, '$regexFindAll': 0, '$regexMatch': 0, '$replaceAll': 0, '$replaceOne': 0, '$reverseArray': 0, '$round': 0, '$rtrim': 0, '$second': 0, '$setDifference': 0, '$setEquals': 0, '$setIntersection': 0, '$setIsSubset': 0, '$setUnion': 0, '$sin': 0, '$sinh': 0, '$size': 0, '$slice': 0, '$split': 0, '$sqrt': 0, '$stdDevPop': 0, '$stdDevSamp': 0, '$strLenBytes': 0, '$strLenCP': 0, '$strcasecmp': 0, '$substr': 0, '$substrBytes': 0, '$substrCP': 0, '$subtract': 0, '$sum': 0, '$switch': 0, '$tan': 0, '$tanh': 0, '$toBool': 0, '$toDate': 0, '$toDecimal': 0, '$toDouble': 0, '$toHashedIndexKey': 0, '$toInt': 0, '$toLong': 0, '$toLower': 0, '$toObjectId': 0, '$toString': 0, '$toUpper': 0, '$trim': 0, '$trunc': 0, '$type': 0, '$week': 0, '$year': 0, '$zip': 0}, 'match': {'$all': 0, '$alwaysFalse': 0, '$alwaysTrue': 0, '$and': 0, '$bitsAllClear': 0, '$bitsAllSet': 0, '$bitsAnyClear': 0, '$bitsAnySet': 0, '$comment': 0, '$elemMatch': 0, '$eq': 0, '$exists': 0, '$expr': 0, '$geoIntersects': 0, '$geoWithin': 0, '$gt': 0, '$gte': 0, '$in': 0, '$jsonSchema': 0, '$lt': 0, '$lte': 0, '$mod': 0, '$ne': 0, '$near': 0, '$nearSphere': 0, '$nin': 0, '$nor': 0, '$not': 0, '$or': 0, '$regex': 0, '$sampleRate': 0, '$size': 0, '$text': 0, '$type': 0, '$where': 0}}, 'query': {'deleteManyCount': 0, 'planCacheTotalSizeEstimateBytes': 0, 'updateDeleteManyDocumentsMaxCount': 0, 'updateDeleteManyDocumentsTotalCount': 0, 'updateDeleteManyDurationMaxMs': 0, 'updateDeleteManyDurationTotalMs': 0, 'updateManyCount': 0, 'updateOneOpStyleBroadcastWithExactIDCount': 0, 'multiPlanner': {'classicCount': 0, 'classicMicros': 0, 'classicWorks': 0, 'histograms': {'classicMicros': [{'lowerBound': 0, 'count': 0}, {'lowerBound': 1024, 'count': 0}, {'lowerBound': 4096, 'count': 0}, {'lowerBound': 16384, 'count': 0}, {'lowerBound': 65536, 'count': 0}, {'lowerBound': 262144, 'count': 0}, {'lowerBound': 1048576, 'count': 0}, {'lowerBound': 4194304, 'count': 0}, {'lowerBound': 16777216, 'count': 0}, {'lowerBound': 67108864, 'count': 0}, {'lowerBound': 268435456, 'count': 0}, {'lowerBound': 1073741824, 'count': 0}], 'classicNumPlans': [{'lowerBound': 0, 'count': 0}, {'lowerBound': 2, 'count': 0}, {'lowerBound': 4, 'count': 0}, {'lowerBound': 8, 'count': 0}, {'lowerBound': 16, 'count': 0}, {'lowerBound': 32, 'count': 0}], 'classicWorks': [{'lowerBound': 0, 'count': 0}, {'lowerBound': 128, 'count': 0}, {'lowerBound': 256, 'count': 0}, {'lowerBound': 512, 'count': 0}, {'lowerBound': 1024, 'count': 0}, {'lowerBound': 2048, 'count': 0}, {'lowerBound': 4096, 'count': 0}, {'lowerBound': 8192, 'count': 0}, {'lowerBound': 16384, 'count': 0}, {'lowerBound': 32768, 'count': 0}]}}}, 'queryExecutor': {'scanned': 0, 'scannedObjects': 0, 'collectionScans': {'nonTailable': 0, 'total': 0}}, 'record': {'moves': 0}, 'repl': {'executor': {'pool': {'inProgressCount': 0}, 'queues': {'networkInProgress': 0, 'sleepers': 0}, 'unsignaledEvents': 0, 'shuttingDown': False, 'networkInterface': 'DEPRECATED: getDiagnosticString is deprecated in NetworkInterfaceTL'}, 'apply': {'attemptsToBecomeSecondary': 0, 'batchSize': 0, 'batches': {'num': 0, 'totalMillis': 0}, 'ops': 0}, 'buffer': {'count': 0, 'maxSizeBytes': 0, 'sizeBytes': 0}, 'initialSync': {'completed': 0, 'failedAttempts': 0, 'failures': 0}, 'network': {'bytes': 0, 'getmores': {'num': 0, 'totalMillis': 0, 'numEmptyBatches': 0}, 'notPrimaryLegacyUnacknowledgedWrites': 0, 'notPrimaryUnacknowledgedWrites': 0, 'oplogGetMoresProcessed': {'num': 0, 'totalMillis': 0}, 'ops': 0, 'readersCreated': 0, 'replSetUpdatePosition': {'num': 0}}, 'stateTransition': {'lastStateTransition': '', 'userOperationsKilled': 0, 'userOperationsRunning': 0}, 'syncSource': {'numSelections': 0, 'numTimesChoseDifferent': 0, 'numTimesChoseSame': 0, 'numTimesCouldNotFind': 0}}, 'ttl': {'deletedDocuments': 0, 'passes': 0}}, 'ok': 1.0}\n",
            "Insert operation result: 67a6b0b88d113faadd8e17b4\n",
            "Read operation result: {'_id': ObjectId('67a6b0b88d113faadd8e17b4'), 'name': 'test', 'value': 123}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  Insert Sample Actors with Mongo Shell Commands"
      ],
      "metadata": {
        "id": "E9sWzG8KIBfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) We'll prepare a multiline string for data insertion.\n",
        "insert_actors = \"\"\"\n",
        "db.actors.insert({\n",
        "  \"name\": \"ActorBorn1956\",\n",
        "  \"dateOfBirth\": ISODate(\"1956-05-10T00:00:00Z\")\n",
        "});\n",
        "\n",
        "db.actors.insert({\n",
        "  \"name\": \"ActorBorn1958\",\n",
        "  \"dateOfBirth\": ISODate(\"1958-03-01T00:00:00Z\")\n",
        "});\n",
        "\n",
        "db.actors.insert({\n",
        "  \"name\": \"ActorBorn1930\",\n",
        "  \"dateOfBirth\": ISODate(\"1930-07-20T00:00:00Z\")\n",
        "});\n",
        "\"\"\"\n",
        "\n",
        "# 2) Execute the shell commands\n",
        "!mongo --quiet --eval '{insert_actors}'\n",
        "\n",
        "print(\"Inserted 3 sample actors into the 'actors' collection.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eId1aFkUIFBn",
        "outputId": "7ec9a295-b271-4098-8be0-a6870984ce43"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WriteResult({ \"nInserted\" : 1 })\n",
            "Inserted 3 sample actors into the 'actors' collection.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Confirm Insert with find().pretty()"
      ],
      "metadata": {
        "id": "9P6v_LdUKalI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "check_insert = \"\"\"\n",
        "db.actors.find().pretty()\n",
        "\"\"\"\n",
        "!mongo --quiet --eval '{check_insert}'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fabhniBzKhgP",
        "outputId": "19ddeff0-62bc-46fc-cdb8-e30650f48121"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "\t\"_id\" : ObjectId(\"67a6b294e4e06b976387ce87\"),\n",
            "\t\"name\" : \"ActorBorn1956\",\n",
            "\t\"dateOfBirth\" : ISODate(\"1956-05-10T00:00:00Z\")\n",
            "}\n",
            "{\n",
            "\t\"_id\" : ObjectId(\"67a6b294e4e06b976387ce88\"),\n",
            "\t\"name\" : \"ActorBorn1958\",\n",
            "\t\"dateOfBirth\" : ISODate(\"1958-03-01T00:00:00Z\")\n",
            "}\n",
            "{\n",
            "\t\"_id\" : ObjectId(\"67a6b294e4e06b976387ce89\"),\n",
            "\t\"name\" : \"ActorBorn1930\",\n",
            "\t\"dateOfBirth\" : ISODate(\"1930-07-20T00:00:00Z\")\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the “Correct” Queries"
      ],
      "metadata": {
        "id": "sbSwCc8vKoVB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Option (i): findOne with \"$lt: ISODate(...)\"\n",
        "query = \"\"\"\n",
        "db.actors.find(\n",
        ").pretty();\n",
        "\"\"\"\n",
        "\n",
        "!mongo --quiet --eval '{query}'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XenhIUyiKqeE",
        "outputId": "79fedc4c-c9ce-4606-d6da-1a568fd1e76a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "\t\"_id\" : ObjectId(\"67a6b294e4e06b976387ce87\"),\n",
            "\t\"name\" : \"ActorBorn1956\",\n",
            "\t\"dateOfBirth\" : ISODate(\"1956-05-10T00:00:00Z\")\n",
            "}\n",
            "{\n",
            "\t\"_id\" : ObjectId(\"67a6b294e4e06b976387ce88\"),\n",
            "\t\"name\" : \"ActorBorn1958\",\n",
            "\t\"dateOfBirth\" : ISODate(\"1958-03-01T00:00:00Z\")\n",
            "}\n",
            "{\n",
            "\t\"_id\" : ObjectId(\"67a6b294e4e06b976387ce89\"),\n",
            "\t\"name\" : \"ActorBorn1930\",\n",
            "\t\"dateOfBirth\" : ISODate(\"1930-07-20T00:00:00Z\")\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## SECTION 4: Question (j) – RecipeML & DTD"
      ],
      "metadata": {
        "id": "Z3rTSDIyJnkY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Context\n",
        "We have a DTD snippet for a <recipe> element:\n",
        "```\n",
        "<!ELEMENT recipe (head, description*, equipment?, ingredients, directions, nutrition?, diet-exchanges?)>\n",
        "```\n",
        "Wanted statements: e.g. \"exactly one <ingredients>\", \"it must come before <directions>\", etc.\n",
        "\n",
        "Below we show a minimal recipe snippet that obeys that order."
      ],
      "metadata": {
        "id": "xD2KvHoOJryk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create a Minimal DTD & Save to File"
      ],
      "metadata": {
        "id": "6lBY44YiJzzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dtd_content = \"\"\"\\\n",
        "<!ELEMENT recipe (head, description*, equipment?, ingredients, directions, nutrition?, diet-exchanges?)>\n",
        "<!ELEMENT head (#PCDATA)>\n",
        "<!ELEMENT description (#PCDATA)>\n",
        "<!ELEMENT equipment (#PCDATA)>\n",
        "<!ELEMENT ingredients (item+)>\n",
        "<!ELEMENT item (#PCDATA)>\n",
        "<!ATTLIST item qty CDATA #IMPLIED>\n",
        "<!ELEMENT directions (#PCDATA)>\n",
        "<!ELEMENT nutrition (#PCDATA)>\n",
        "<!ELEMENT diet-exchanges (#PCDATA)>\n",
        "\n",
        "<!-- For demonstration, we skip real definitions of %common.att; %measurement.att; -->\n",
        "\"\"\"\n",
        "\n",
        "# We'll write it to a local file called recipe.dtd\n",
        "with open(\"recipe.dtd\", \"w\") as f:\n",
        "    f.write(dtd_content)\n",
        "\n",
        "print(\"Created recipe.dtd with minimal structure.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InTD5RqCM3So",
        "outputId": "6d4be498-485c-4a24-b7fc-7d3707bbcb93"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created recipe.dtd with minimal structure.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the Recipe XML snippet referencing `recipe.dtd`"
      ],
      "metadata": {
        "id": "4Yp1m6zINDDv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recipe_xml = \"\"\"\\\n",
        "<!DOCTYPE recipe SYSTEM \"recipe.dtd\">\n",
        "<recipe>\n",
        "   <head>Example Recipe Head</head>\n",
        "   <description>Quick description line 1</description>\n",
        "   <description>Quick description line 2</description>\n",
        "   <ingredients>\n",
        "     <item qty=\"2\">Eggs</item>\n",
        "   </ingredients>\n",
        "   <directions>Beat eggs thoroughly</directions>\n",
        "</recipe>\n",
        "\"\"\"\n",
        "\n",
        "with open(\"test_recipe.xml\", \"w\") as f:\n",
        "    f.write(recipe_xml)\n",
        "\n",
        "print(\"Created test_recipe.xml referencing our minimal DTD.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SfKH2mioJywC",
        "outputId": "a29aec92-9cb4-4d14-875b-9f53b0a0ee04"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Created test_recipe.xml referencing our minimal DTD.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validate the XML Using lxml"
      ],
      "metadata": {
        "id": "wYW6_vw6NS9-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from lxml import etree\n",
        "\n",
        "# Create parser with DTD validation\n",
        "parser = etree.XMLParser(dtd_validation=True, load_dtd=True)\n",
        "try:\n",
        "    tree = etree.parse(\"test_recipe.xml\", parser)\n",
        "    print(\"DTD validation: SUCCESS. The XML conforms to the minimal DTD.\")\n",
        "except etree.XMLSyntaxError as e:\n",
        "    print(\"DTD validation: FAILED!\")\n",
        "    print(\"Reason:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcAtW4_7JqqQ",
        "outputId": "c3027c20-889f-4957-ab17-15f753132d70"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DTD validation: SUCCESS. The XML conforms to the minimal DTD.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wwBsHjEfNZFT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}